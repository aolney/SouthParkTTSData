{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Forced Alignment Notes for Southpark TTS Data\n",
    "\n",
    "The purpose of this notebook is to record some of the exploration around the topic of forced aligment for these data.\n",
    "\n",
    "For a full description of the steps leading up to generating wav files and srt files, see the main notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## CCAligner\n",
    "\n",
    "One tool specifically designed to work with subtitle data is [CCAligner](https://github.com/saurabhshri/CCAligner/blob/master/README.adoc). \n",
    "\n",
    "### CCAligner: Single file example\n",
    "\n",
    "See main notebook for running large batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cd \"/vm/CCAligner/install\"\n",
    "echo \"In $PWD\"\n",
    "#-audioWindow 500 -searchWindow 6 -useBatchMode yes\n",
    "./ccaligner -wav /y/south-park-1-to-20/1-1.wav -srt /y/south-park-1-to-20/1-1.srt -oFormat json >> ccalign.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### CCAligner: Evaluations\n",
    "\n",
    "\n",
    "#### Comparison to SRT\n",
    "\n",
    "We load up SRT and CCAligner outputs for the same disc and evaluate the times:\n",
    "\n",
    "- Subtitle times (when it appears and disappears); compare across SRT and CCAligner\n",
    "- Number of words recognized (only in CCAligner)\n",
    "- Word alignment times (only in CCAligner)\n",
    "\n",
    "Comparison between SRT and CCAligner times is approximate b/c ccaligner changes strings. \n",
    "Some strings will not be matched at all (missing at random?); some repeated strings will be matched in the wrong location (false difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "#r \"/z/aolney/repos/Newtonsoft.Json.9.0.1/lib/net40/Newtonsoft.Json.dll\"\n",
    "\n",
    "type Word =\n",
    "    {\n",
    "        word : string\n",
    "        recognised : int //logical 1/0\n",
    "        start : int\n",
    "        ``end`` : int\n",
    "        duration : int\n",
    "    }\n",
    "    \n",
    "type Subtitle =\n",
    "    {\n",
    "        subtitle : string\n",
    "        edited_text : string\n",
    "        start : int\n",
    "        ``end`` : int\n",
    "        words: Word[]\n",
    "    }\n",
    "    override x.ToString() = x.edited_text + \"-\" + x.start.ToString()  + \":\" + x.``end``.ToString()\n",
    "\n",
    "type CCAligned =\n",
    "    {\n",
    "        subtitles : Subtitle[]\n",
    "    }\n",
    "    \n",
    "///The CCAligned json is invalid; we must fix unescaped quotes and put commas b/w objects\n",
    "let FixCCAlignedJSON filePath =\n",
    "    let json = \n",
    "        filePath\n",
    "        |> System.IO.File.ReadAllLines\n",
    "        |> Seq.map( fun line -> line.Replace(\"} {\",\"},  {\"))\n",
    "        |> Seq.map( fun line -> line.Replace(\"}\\t{\",\"},  {\")) //new version of json.net requires\n",
    "        |> Seq.map( fun line -> line.Replace(\"\\\\\",\"\")) //bad escape sequences - bad OCR?\n",
    "        |> Seq.map( fun line ->\n",
    "                   let fieldIndex = line.IndexOf(\":\")\n",
    "                   if fieldIndex > 0 then \n",
    "                       let propertyString = line.Substring(fieldIndex+1)\n",
    "                       if propertyString.Contains(\"\\\"\") then\n",
    "                           line.Substring(0,fieldIndex + 1) + \"\\\"\" + propertyString.Trim([|' ';'\"';','|]).Replace(\"\\\"\",\"\\\\\\\"\") + \"\\\",\"\n",
    "                       else\n",
    "                           line\n",
    "                   else \n",
    "                       line\n",
    "                  )\n",
    "    //System.IO.File.WriteAllLines( filePath + \".corrected\",json )\n",
    "    //let correctedJson = System.IO.File.ReadAllText( filePath + \".corrected\" )\n",
    "    let ccAligned = Newtonsoft.Json.JsonConvert.DeserializeObject<CCAligned>(json |> String.concat \"\\n\" ) //correctedJson)\n",
    "    //\n",
    "    ccAligned\n",
    "\n",
    "let SrtStringToTime( timeString ) =  \n",
    "    System.TimeSpan.ParseExact(timeString, @\"hh\\:mm\\:ss\\,fff\", null).TotalMilliseconds\n",
    "let blankLinesRegex = new System.Text.RegularExpressions.Regex(\"\\n\\n+\")\n",
    "let RegexSplit (regex : System.Text.RegularExpressions.Regex)  (input:string) = regex.Split( input )\n",
    "let SubtitlesFromSRT filePath = \n",
    "    ( filePath |> System.IO.File.ReadAllText).Trim() \n",
    "    |> RegexSplit blankLinesRegex \n",
    "    //Split([|\"\\n\\n\"|],System.StringSplitOptions.None)\n",
    "    |> Array.map(fun block ->\n",
    "        let blockLines = block.Split('\\n')\n",
    "        if blockLines.[1].Contains( \" --> \") |> not then\n",
    "            System.Console.WriteLine()\n",
    "        let startEnd = blockLines.[1].Replace( \" --> \", \" \").Trim().Split(' ')\n",
    "        let start = startEnd.[0] |> SrtStringToTime |> int\n",
    "        let stop = startEnd.[1] |> SrtStringToTime |> int\n",
    "        let subtitle = blockLines |> Array.skip 2 |> String.concat \" \"\n",
    "        { subtitle = subtitle ; edited_text = \"\"; start = start;  ``end`` = stop ; words = [||]}\n",
    "        )\n",
    "    \n",
    "let CompareSrtAndCCAlign srtDirectory alignedDirectory =\n",
    "    let fileTuples = \n",
    "        Seq.zip \n",
    "            ( System.IO.Directory.GetFiles(srtDirectory, \"*.srt\") |> Seq.sort )\n",
    "            ( System.IO.Directory.GetFiles(alignedDirectory, \"*.json\") |> Seq.sort )\n",
    "\n",
    "    //this is approximate b/c ccAligner changes the text slightly for some subtitles\n",
    "    let srtCCAlignSubtitleCorrespondence =\n",
    "        fileTuples\n",
    "        |> Seq.collect( fun (srtFile,alignedFile) ->\n",
    "            let srtMap = srtFile |> SubtitlesFromSRT |> Seq.groupBy( fun subtitle -> subtitle.subtitle ) |> Map.ofSeq\n",
    "            let ccAligned = alignedFile |> FixCCAlignedJSON\n",
    "            ccAligned.subtitles\n",
    "            |> Seq.choose( fun aSubtitle -> \n",
    "                match srtMap.TryFind( aSubtitle.subtitle ) with\n",
    "                | Some( subSequence ) -> \n",
    "                    let closestSubtitleToSRT =\n",
    "                        subSequence \n",
    "                        |> Seq.sortBy( fun s -> System.Math.Abs( aSubtitle.start - s.start ) ) \n",
    "                        |> Seq.head \n",
    "                    let isMatch,matchString =\n",
    "                        if closestSubtitleToSRT.start = aSubtitle.start && closestSubtitleToSRT.``end`` = aSubtitle.``end`` then \n",
    "                            true,\"SAME\"\n",
    "                        else \n",
    "                            false,\"DIFF\"\n",
    "                    Some(\n",
    "                        (isMatch, srtFile + \"\\t\" + aSubtitle.edited_text + \"\\t\" + aSubtitle.start.ToString() + \"\\t\" + aSubtitle.``end``.ToString() + \"\\t\" + \n",
    "                            closestSubtitleToSRT.subtitle  + \"\\t\" + closestSubtitleToSRT.start.ToString() + \"\\t\" +  closestSubtitleToSRT.``end``.ToString()  + \"\\t\" + matchString)\n",
    "                        )\n",
    "                | None -> None\n",
    "            )   \n",
    "        )\n",
    "    System.IO.File.WriteAllLines( \"srt-aligned-correspondence-\" + System.DateTime.Now.ToString(\"s\").Replace(\" \",\"-\").Replace(\":\",\"_\") + \".tsv\", srtCCAlignSubtitleCorrespondence |> Seq.map snd )\n",
    "\n",
    "//Compare with default CCAlign\n",
    "//CompareSrtAndCCAlign \"/y/south-park-1-to-20/\" \"/y/south-park-1-to-20/ccalign-json-default\"\n",
    "//CompareSrtAndCCAlign \"/y/south-park-1-to-20/\" \"/y/south-park-1-to-20/ccalign-json-audioWindow500\"\n",
    "\n",
    "//Count percentage of recognized words\n",
    "let PercentRecognized alignedDirectory =\n",
    "    let words = \n",
    "        System.IO.Directory.GetFiles(alignedDirectory, \"*.json\") \n",
    "        |> Seq.collect( fun alignedFile -> \n",
    "            (alignedFile |> FixCCAlignedJSON).subtitles \n",
    "            |> Seq.collect( fun s -> s.words ) )\n",
    "    let totalWords = words |> Seq.length |> float\n",
    "    let recognizedWords = words |> Seq.sumBy( fun w -> w.recognised ) |> float\n",
    "    //\n",
    "    (recognizedWords/totalWords).ToString()\n",
    "    \n",
    "//Percent recognized; notebook output (crashes mono)\n",
    "[\n",
    "    \"default\" ; PercentRecognized \"/y/south-park-1-to-20/ccalign-json-default\";\n",
    "    \"audioWindow500\" ; PercentRecognized \"/y/south-park-1-to-20/ccalign-json-audioWindow500\";\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### CCAligner: Results\n",
    "\n",
    "1. CCAligner's start/end at the subtitle level is not changed by audio parameters. So unless word timings are going to be used for alignment, CCAligner adds no value over SRT.\n",
    "2. Listening to wav in Audacity at the start/end points of the word alignments indicate they are usually OK **when the word is recognized**; even still there is some clipping around words. \n",
    "3. If the word is not recognized, the alignments are not good at all.\n",
    "4. Percent correct words recognized\n",
    "    - Using default settings on CCAligner (default + useBatchMode) gives 31% recognized words\n",
    "    - Using audioWindow = 500 with useBatchMode gives 33% recognized words\n",
    "    - The relative improvement between these settings is not clear\n",
    "\n",
    "**Overall, CCAligner seems marginally viable for South Park. It probably isn't better than using the SRT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "# aeneas\n",
    "\n",
    "[aeneas](https://www.readbeyond.it/aeneas/) was investigated to see if it improved performance relative to CCAligner.\n",
    "\n",
    "Using aeneas required reformatting the srt file into a suitable text file. \n",
    "The code below creates a whole disc of text.\n",
    "This file was also used in later evaluations of whole disc text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "//create plain text file from srt https://www.readbeyond.it/aeneas/docs/textfile.html#aeneas.textfile.TextFileFormat.PLAIN\n",
    "let whiteSpaceRegex = System.Text.RegularExpressions.Regex(\"\\s+\")\n",
    "let nonApostrophePunctRegex = System.Text.RegularExpressions.Regex(\"[^\\w\\s']\")\n",
    "let RemovePunctuation inputString =\n",
    "    whiteSpaceRegex.Replace( nonApostrophePunctRegex.Replace( inputString, \" \"), \" \" ).Trim()\n",
    "let tagRegex = System.Text.RegularExpressions.Regex(\"<.*?>\") //only acceptable b/c our subtitle markup is so simplistic it does not require CFG parser\n",
    "let RemoveTags inputString =\n",
    "    whiteSpaceRegex.Replace( tagRegex.Replace( inputString, \" \"), \" \" ).Trim()\n",
    "\n",
    "let lines =\n",
    "    (\"/y/south-park-1-to-20/1-1.srt\" |> System.IO.File.ReadAllText).Trim().Split(\"\\n\\n\")\n",
    "    |> Seq.map(fun block ->\n",
    "        let text =\n",
    "            block.Split(\"\\n\")\n",
    "            |> Seq.skip 2\n",
    "            |> String.concat \" \"\n",
    "            |> RemoveTags\n",
    "        text\n",
    "              )\n",
    "System.IO.File.WriteAllLines(\"1-1.foraeneas\", lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "ifsharp"
   },
   "source": [
    "### aeneas: Whole Disc Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "python -m aeneas.tools.execute_task \\\n",
    "   /y/south-park-1-to-20/1-1.wav \\\n",
    "   1-1.foraeneas \\\n",
    "   \"task_language=eng|os_task_file_format=json|is_text_type=plain\" \\\n",
    "   1-1.aeneas.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### aeneas: Whole Disc Results\n",
    "\n",
    "Aeneas lost alignment by a minute or two into the whole disc.\n",
    "The first minute (real speech, not character voices) had good alignment.\n",
    "\n",
    "### aeneas: Clip Evaluation, Strict SRT\n",
    "\n",
    "The first couple of utterances looked plausible though, so the evaluation was repeated using the following methodology:\n",
    "\n",
    "- Using SRT to get clip for alignment, where clip consists of multiple subtitles\n",
    "- Extract WAV file using the SRT clip boundaries\n",
    "- Use corresponding text of clip\n",
    "\n",
    "The first text block evaluated was\n",
    "```\n",
    "AND NOW A FIRESIDE CHAT\n",
    "WITH THE CREATORS OF COMEDY CENTRAL'S SOUTH PARK\n",
    "MATT STONE AND TREY PARKER\n",
    "```\n",
    "The second block was\n",
    "```\n",
    "THEN I WAS LYING ON A TABLE\n",
    "AND THESE SCARY ALIENS WANTED TO OPERATE ON ME.\n",
    "AND THEY HAD BIG HEADS AND BIG BLACK EYES.\n",
    "DUDE, VISITORS!\n",
    "TOTALLY!\n",
    "WHAT?\n",
    "THAT WASN'T A DREAM, CARTMAN.\n",
    "THOSE WERE VISITORS!\n",
    "NO, IT WAS JUST A DREAM.\n",
    "MY MOM SAID SO.\n",
    "```\n",
    "\n",
    "The third block was the same as the second but with one word per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Validating config string (specify --skip-validator to bypass)...\n",
      "[INFO] Validating config string... done\n",
      "[INFO] Creating task...\n",
      "[INFO] Creating task... done\n",
      "[INFO] Executing task...\n",
      "[INFO] Executing task... done\n",
      "[INFO] Creating output sync map file...\n",
      "[INFO] Creating output sync map file... done\n",
      "\u001b[92m[INFO] Created file '1-1-clip1.json'\u001b[0m\n",
      "[INFO] Validating config string (specify --skip-validator to bypass)...\n",
      "[INFO] Validating config string... done\n",
      "[INFO] Creating task...\n",
      "[INFO] Creating task... done\n",
      "[INFO] Executing task...\n",
      "[INFO] Executing task... done\n",
      "[INFO] Creating output sync map file...\n",
      "[INFO] Creating output sync map file... done\n",
      "\u001b[92m[INFO] Created file '1-1-clip2.json'\u001b[0m\n",
      "[INFO] Validating config string (specify --skip-validator to bypass)...\n",
      "[INFO] Validating config string... done\n",
      "[INFO] Creating task...\n",
      "[INFO] Creating task... done\n",
      "[INFO] Executing task...\n",
      "[INFO] Executing task... done\n",
      "[INFO] Creating output sync map file...\n",
      "[INFO] Creating output sync map file... done\n",
      "\u001b[92m[INFO] Created file '1-1-clip2words.json'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "python -m aeneas.tools.execute_task \\\n",
    "   1-1-clip1.wav \\\n",
    "   1-1-clip1.txt \\\n",
    "   \"task_language=eng|os_task_file_format=json|is_text_type=plain\" \\\n",
    "   1-1-clip1.json\n",
    "\n",
    "python -m aeneas.tools.execute_task \\\n",
    "   1-1-clip2.wav \\\n",
    "   1-1-clip2.txt \\\n",
    "   \"task_language=eng|os_task_file_format=json|is_text_type=plain\" \\\n",
    "   1-1-clip2.json\n",
    "\n",
    "python -m aeneas.tools.execute_task \\\n",
    "   1-1-clip2.wav \\\n",
    "   1-1-clip2words.txt \\\n",
    "   \"task_language=eng|os_task_file_format=json|is_text_type=plain\" \\\n",
    "   1-1-clip2words.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### aeneas: Clip Results, Strict SRT\n",
    "\n",
    "- Clip 1: Reasonable for narrator speech. Was not that different from SRT boundaries, but was a little tighter on the ends\n",
    "- Clip 2: When given longer clip 'THEN - EYES', does a better job of finding the end boundary than the SRT; However, next turn is already off by one word.\n",
    "- Clip 2words: Had different errors than Clip 2, but was similarly off\n",
    "\n",
    "Based on these results, a reasonable question is whether we can \"pad\" the SRT boundaries and find some words within them. \n",
    "We call this \"loose\" SRT.\n",
    "\n",
    "### aeneas: Clip Results, Loose SRT\n",
    "\n",
    "Using just the following text, with SRT times +/- 1s\n",
    "\n",
    "```\n",
    "DUDE, VISITORS!\n",
    "TOTALLY!\n",
    "WHAT?\n",
    "```\n",
    "\n",
    "And again, with SRT +/1 500ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Validating config string (specify --skip-validator to bypass)...\n",
      "[INFO] Validating config string... done\n",
      "[INFO] Creating task...\n",
      "[INFO] Creating task... done\n",
      "[INFO] Executing task...\n",
      "[INFO] Executing task... done\n",
      "[INFO] Creating output sync map file...\n",
      "[INFO] Creating output sync map file... done\n",
      "\u001b[92m[INFO] Created file '1-1-clip3.json'\u001b[0m\n",
      "[INFO] Validating config string (specify --skip-validator to bypass)...\n",
      "[INFO] Validating config string... done\n",
      "[INFO] Creating task...\n",
      "[INFO] Creating task... done\n",
      "[INFO] Executing task...\n",
      "[INFO] Executing task... done\n",
      "[INFO] Creating output sync map file...\n",
      "[INFO] Creating output sync map file... done\n",
      "\u001b[92m[INFO] Created file '1-1-clip4.json'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "python -m aeneas.tools.execute_task \\\n",
    "   1-1-clip3.wav \\\n",
    "   1-1-clip3.txt \\\n",
    "   \"task_language=eng|os_task_file_format=json|is_text_type=plain\" \\\n",
    "   1-1-clip3.json\n",
    "\n",
    "python -m aeneas.tools.execute_task \\\n",
    "   1-1-clip4.wav \\\n",
    "   1-1-clip3.txt \\\n",
    "   \"task_language=eng|os_task_file_format=json|is_text_type=plain\" \\\n",
    "   1-1-clip4.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### aeneas: Clip Results, Loose SRT\n",
    "\n",
    "- Clip 3: Was basically totally garbage\n",
    "- Clip 4: Same\n",
    "    \n",
    "Looks like aeneas needs pretty clean audio to do the alignment.\n",
    "\n",
    "**Since SRT does not give perfect boundaries, and since we can't align a whole file with aeneas, it doesn't seem that aeneas can be used.**\n",
    "\n",
    "## eesen-transcriber\n",
    "\n",
    "The [vagrant installation method](https://github.com/srvk/eesen-transcriber/blob/master/INSTALL.md) was used to simplify the installation.\n",
    "However, even with vagrant, the installation was fairly complex and required tweaking of various scripts.\n",
    "As a result, it's not clear if eesen was installed correctly, though spot checking suggests that the ASR was working correctly.\n",
    "\n",
    "Example usage for alignment is `vagrant ssh -c \"align.sh /vagrant/1-1.wav\"` with the corresponding STM file in the same directory as the wav (i.e. the vagrant directory). The STM was created [using the SRT file](https://git.capio.ai/pub/srt-to-stm-converter).\n",
    "\n",
    "### eesen-transcriber: Whole disc results\n",
    "\n",
    "Even the begining was significantly shifted in time:\n",
    "\n",
    "```\n",
    "1-1-A---0005.610-0006.610 1 5.61 0.06 now\n",
    "1-1-A---0005.610-0006.610 1 5.67 0.00 a\n",
    "1-1-A---0005.610-0006.610 1 5.67 0.00 fireside\n",
    "1-1-A---0005.610-0006.610 1 5.67 0.93 chat\n",
    "1-1-A---0006.610-0008.610 1 6.61 0.03 the\n",
    "1-1-A---0006.610-0008.610 1 6.64 0.06 creators\n",
    "```\n",
    "\n",
    "When the kids start speaking, the alignments get very spotty:\n",
    "\n",
    "```\n",
    "1-1-A---0178.280-0179.780 1 178.31 0.00 my\n",
    "1-1-A---0178.280-0179.780 1 178.31 0.21 little\n",
    "1-1-A---0178.280-0179.780 1 178.52 1.26 brother's\n",
    "1-1-A---0180.780-0183.280 1 180.78 0.06 <unk>\n",
    "1-1-A---0180.780-0183.280 1 180.84 0.00 <unk>\n",
    "1-1-A---0184.280-0186.780 1 184.28 0.09 he\n",
    "1-1-A---0184.280-0186.780 1 184.37 0.33 <unk>\n",
    "1-1-A---0184.280-0186.780 1 184.70 0.57 he\n",
    "1-1-A---0184.280-0186.780 1 185.27 0.72 <unk>\n",
    "1-1-A---0186.790-0188.790 1 186.79 0.84 <unk>\n",
    "1-1-A---0188.790-0189.790 1 188.79 0.03 don't\n",
    "1-1-A---0188.790-0189.790 1 188.82 0.15 call\n",
    "1-1-A---0188.790-0189.790 1 188.97 0.09 my\n",
    "1-1-A---0188.790-0189.790 1 189.06 0.60 brother\n",
    "```\n",
    "\n",
    "Overall,  eesen-transcriber does not seem viable for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "# Gentle\n",
    "\n",
    "The [docker installation method](https://github.com/lowerquality/gentle) was used to reduce the effort of installation, but the run instructions had to be adapted to: `docker run -p 8765:8765  lowerquality/gentle`\n",
    "\n",
    "Example usage is `curl -F \"audio=@audio.mp3\" -F \"transcript=@words.txt\" \"http://0.0.0.0:8765/transcriptions?async=false\"`\n",
    "\n",
    "### Gentle: parameters\n",
    "\n",
    "Additional parameters are `?async=false&disfluency=true&conservative=true`\n",
    "\n",
    "The meanings of these parameters appear to be\n",
    "\n",
    "> Use the given token sequence to make a bigram language model\n",
    ">    in OpenFST plain text format.\n",
    ">    When the \"conservative\" flag is set, an [oov] is interleaved\n",
    ">    between successive words.\n",
    ">    When the \"disfluency\" flag is set, a small set of disfluencies is\n",
    ">    interleaved between successive words\n",
    ">    `Word sequence` is a list of lists, each valid as a start\n",
    "\n",
    "### Gentle: Whole disc example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "date\n",
    "curl -F \"audio=@/y/south-park-1-to-20/1-1.wav\" -F \"transcript=@1-1.foraeneas\" \"http://0.0.0.0:8765/transcriptions?async=false&disfluency=true&conservative=true\" -o 1-1.gentle.json\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Gentle: Whole Disc Results\n",
    "\n",
    "Gentle was fairly excellent. Spot checking showed alignment was still good at minutes 23, 59, 1:14, 1:30, and 1:33.\n",
    "\n",
    "# Overall Results\n",
    "\n",
    "**Based on these results, it seems plausible to use Gentle for alignment at the whole disc level.**\n",
    "\n",
    "It does not appear necessary to manually check alignments if Gentle is used. \n",
    "However, tools like [finetuneas](https://github.com/ozdefir/finetuneas) that facilitate this process exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "ifsharp",
     "ifsharp",
     "",
     ""
    ]
   ],
   "version": "0.9.15.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
