{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# South Park TTS Data\n",
    "\n",
    "The purpose of this [SoS notebook](https://vatlab.github.io/sos-docs/) is to prepare a dataset for learning a text to speech (TTS) system from South Park video data.\n",
    "\n",
    "The general pipeline is applicable to creating TTS data when subtitles are available, *except* for the speaker identification component used here, which requires South Park transcripts with speaker annotations.\n",
    "It's possible that the method of speaker identification used here would translate to other datasets that had some type of speaker annotation, but this would likely require some nontrivial modification.\n",
    "\n",
    "Creating the South Park TTS dataset involved the following steps:\n",
    "\n",
    "1. Convert DVDs\n",
    "2. Extract subtitles\n",
    "3. Align subtitles with audio sufficiently for labeled data needs\n",
    "4. Do speaker identification\n",
    "5. Create WAV/transcript data in suitable format (e.g. [LJSpeech](https://keithito.com/LJ-Speech-Dataset/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## DVD conversion\n",
    "\n",
    "Originally the goal was to just get the ISOs for the DVDs to allow batch processing.\n",
    "However, strange obfuscation was used on the DVDs, presumably to prevent copyright infringement.\n",
    "As a result, each DVD had to be transcoded to MP4 using Handbrake. \n",
    "This was the only option of those tried that preserved the subtitle information.\n",
    "The following manual steps were used:\n",
    "\n",
    "- Discs up to season 13 where converted to ISO using various programs (NOTE: Handbrake could probably have been used instead and would have resulted in more homogenous outputs; some idiosyncratic processing below could possibly have been avoided by using Handbrake everywhere)\n",
    "- Handbrake was run over these and then each succeeding disc\n",
    "    - Seasons 1-12: detelecine + decombe (4:3 format)\n",
    "    - Season 13-17: no detelecine or decombe\n",
    "    - Season 18-20: detelecine + decombe\n",
    "    - Season 15-20: closed captions replaced with image subtitles\n",
    "\n",
    "This is an example settings file for HandBrake 1.1.0 for detelecine + decombe for CC or VobSub\n",
    "```\n",
    "{\n",
    "    \"PresetList\": [\n",
    "        {\n",
    "            \"AlignAVStart\": true,\n",
    "            \"AudioCopyMask\": [\n",
    "                \"copy:aac\"\n",
    "            ],\n",
    "            \"AudioEncoderFallback\": \"av_aac\",\n",
    "            \"AudioLanguageList\": [],\n",
    "            \"AudioList\": [\n",
    "                {\n",
    "                    \"AudioBitrate\": 160,\n",
    "                    \"AudioCompressionLevel\": -1.0,\n",
    "                    \"AudioDitherMethod\": \"auto\",\n",
    "                    \"AudioEncoder\": \"av_aac\",\n",
    "                    \"AudioMixdown\": \"dpl2\",\n",
    "                    \"AudioNormalizeMixLevel\": false,\n",
    "                    \"AudioSamplerate\": \"auto\",\n",
    "                    \"AudioTrackDRCSlider\": 0.0,\n",
    "                    \"AudioTrackGainSlider\": 0.0,\n",
    "                    \"AudioTrackQuality\": 1.0,\n",
    "                    \"AudioTrackQualityEnable\": false\n",
    "                }\n",
    "            ],\n",
    "            \"AudioSecondaryEncoderMode\": true,\n",
    "            \"AudioTrackSelectionBehavior\": \"first\",\n",
    "            \"ChapterMarkers\": true,\n",
    "            \"ChildrenArray\": [],\n",
    "            \"Default\": false,\n",
    "            \"FileFormat\": \"av_mp4\",\n",
    "            \"Folder\": false,\n",
    "            \"FolderOpen\": false,\n",
    "            \"InlineParameterSets\": false,\n",
    "            \"Mp4HttpOptimize\": false,\n",
    "            \"Mp4iPodCompatible\": false,\n",
    "            \"PictureAutoCrop\": true,\n",
    "            \"PictureBottomCrop\": 0,\n",
    "            \"PictureCombDetectCustom\": \"\",\n",
    "            \"PictureCombDetectPreset\": \"default\",\n",
    "            \"PictureDARWidth\": 0,\n",
    "            \"PictureDeblock\": 0,\n",
    "            \"PictureDeblockCustom\": \"qp=0:mode=2\",\n",
    "            \"PictureDeinterlaceCustom\": \"\",\n",
    "            \"PictureDeinterlaceFilter\": \"decomb\",\n",
    "            \"PictureDeinterlacePreset\": \"default\",\n",
    "            \"PictureDenoiseCustom\": \"\",\n",
    "            \"PictureDenoiseFilter\": \"off\",\n",
    "            \"PictureDenoisePreset\": \"\",\n",
    "            \"PictureDenoiseTune\": \"none\",\n",
    "            \"PictureDetelecine\": \"default\",\n",
    "            \"PictureDetelecineCustom\": \"\",\n",
    "            \"PictureForceHeight\": 0,\n",
    "            \"PictureForceWidth\": 0,\n",
    "            \"PictureHeight\": 720,\n",
    "            \"PictureItuPAR\": false,\n",
    "            \"PictureKeepRatio\": true,\n",
    "            \"PictureLeftCrop\": 0,\n",
    "            \"PictureLooseCrop\": false,\n",
    "            \"PictureModulus\": 2,\n",
    "            \"PicturePAR\": \"auto\",\n",
    "            \"PicturePARHeight\": 27,\n",
    "            \"PicturePARWidth\": 32,\n",
    "            \"PictureRightCrop\": 0,\n",
    "            \"PictureRotate\": \"disable=1\",\n",
    "            \"PictureSharpenCustom\": \"\",\n",
    "            \"PictureSharpenFilter\": \"off\",\n",
    "            \"PictureSharpenPreset\": \"\",\n",
    "            \"PictureSharpenTune\": \"\",\n",
    "            \"PictureTopCrop\": 0,\n",
    "            \"PictureWidth\": 1280,\n",
    "            \"PresetDescription\": \"southpark-reconstructed-vobsub-detelecine-decomb\",\n",
    "            \"PresetName\": \"southpark-reconstructed-vobsub-dete-deco\",\n",
    "            \"SubtitleAddCC\": false,\n",
    "            \"SubtitleAddForeignAudioSearch\": true,\n",
    "            \"SubtitleAddForeignAudioSubtitle\": false,\n",
    "            \"SubtitleBurnBDSub\": true,\n",
    "            \"SubtitleBurnBehavior\": \"foreign\",\n",
    "            \"SubtitleBurnDVDSub\": true,\n",
    "            \"SubtitleLanguageList\": [],\n",
    "            \"SubtitleTrackSelectionBehavior\": \"none\",\n",
    "            \"Type\": 1,\n",
    "            \"UsesPictureFilters\": true,\n",
    "            \"UsesPictureSettings\": 1,\n",
    "            \"VideoAvgBitrate\": 3000,\n",
    "            \"VideoColorMatrixCode\": 0,\n",
    "            \"VideoEncoder\": \"x264\",\n",
    "            \"VideoFramerate\": \"30\",\n",
    "            \"VideoFramerateMode\": \"pfr\",\n",
    "            \"VideoGrayScale\": false,\n",
    "            \"VideoLevel\": \"3.1\",\n",
    "            \"VideoOptionExtra\": \"\",\n",
    "            \"VideoPreset\": \"fast\",\n",
    "            \"VideoProfile\": \"main\",\n",
    "            \"VideoQSVAsyncDepth\": 4,\n",
    "            \"VideoQSVDecode\": false,\n",
    "            \"VideoQualitySlider\": 21.0,\n",
    "            \"VideoQualityType\": 2,\n",
    "            \"VideoScaler\": \"swscale\",\n",
    "            \"VideoTune\": \"\",\n",
    "            \"VideoTurboTwoPass\": true,\n",
    "            \"VideoTwoPass\": true,\n",
    "            \"x264Option\": \"\",\n",
    "            \"x264UseAdvancedOptions\": false\n",
    "        }\n",
    "    ],\n",
    "    \"VersionMajor\": 32,\n",
    "    \"VersionMicro\": 0,\n",
    "    \"VersionMinor\": 0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Extract subtitles and wav\n",
    "\n",
    "For CC subtitles (seasons 1-14), `srt` files are easily extracted with:\n",
    "\n",
    "`ffmpeg -txt_format text -i NAME.mp4 NAME.srt`\n",
    "\n",
    "For VobSub, we first need to get the track index for subtitles using [MP4Box](https://gpac.wp.imt.fr/mp4box/), extract `idx`/`sub` files using MP4Box, and then convert these to `srt` using [VobSub2SRT](https://github.com/ruediger/VobSub2SRT). The commands are:\n",
    "\n",
    "`MP4Box -info input.mp4` to get the `sub` track id\n",
    "\n",
    "`MP4Box -raw <trackID> input.mp4` to get the idx/sub\n",
    "\n",
    "`vobsub2srt input.mp4` to convert idx/sub to srt\n",
    "\n",
    "For wav we extract the wav format required by [ccAligner](https://github.com/saurabhshri/CCAligner/blob/master/README.adoc)\n",
    "\n",
    "Also we extract \"chapter\" information, which is a parallel subtitle track. Presumably this could yield episode boundaries. However, perhaps because of the mixture of methods used to extract MP4 above, we find that the chapter information is too inconsistent to be very useful for this project (some discs have no chapters, some have more chapters than episodes, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "mp4Path=\"/y/south-park-1-to-20/\"\n",
    "echo $mp4Path\n",
    "for file in \"$mp4Path\"*.mp4; do\n",
    "    base=\"$(basename \"$file\" .mp4)\"\n",
    "    prefix=${base%-*}\n",
    "    echo \"$file\"\n",
    "    #Get wav\n",
    "    ffmpeg -i \"$file\" -bits_per_raw_sample 16 -ar 16000 -ac 1 \"$mp4Path$base\".wav >> output.txt 2>&1\n",
    "    #Get chapter level information; useful for segmenting episodes out of entire discs\n",
    "    ffprobe -i \"$file\" -print_format json -show_chapters -loglevel error > \"$mp4Path$base\".chapter\n",
    "    #Get srt\n",
    "    if [ \"$prefix\" -gt \"14\" ]; then\n",
    "        MP4Box -raw 3 \"$file\" >> output.txt 2>&1 #note 3 must match output of MP4Box -info\n",
    "        vobsub2srt \"$mp4Path$base\"_track3 >> output.txt 2>&1 #note _track3 must match output of MP4Box -raw\n",
    "    else\n",
    "        #Note this writes to pwd not the mp4 directory\n",
    "        ffmpeg -txt_format text -i \"$file\" \"$base.srt\" >> output.txt 2>&1\n",
    "    fi\n",
    "done\n",
    "cp *.srt \"$mp4Path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Align subtitles to audio/wav\n",
    "\n",
    "For this we use [gentle](https://github.com/lowerquality/gentle).\n",
    "Other forced alignment tools were evaluated in `forced-alignment-notes.ipynb`.\n",
    "\n",
    "CCAligner was originally used, so some code below has legacy connections with that project.\n",
    "\n",
    "The [docker installation method](https://github.com/lowerquality/gentle) was used to reduce the effort of installation, but the run instructions had to be adapted to:\n",
    "```\n",
    "docker run -p 8765:8765  lowerquality/gentle\n",
    "```\n",
    "\n",
    "Example use is \n",
    "```\n",
    "curl -F \"audio=@/y/south-park-1-to-20/1-1.wav\" -F \"transcript=@1-1.txt\" \"http://0.0.0.0:8765/transcriptions?async=false&disfluency=true&conservative=true\" -o 1-1.gentle.json\n",
    "```\n",
    "\n",
    "Our initial evaluations indicate that we can generate the required transcript files simply from the SRT.\n",
    "\n",
    "### Generate needed transcripts from SRT\n",
    "\n",
    "We need raw text transcripts for `gentle`. \n",
    "We generate these using the SRT by loading and cleaning the SRT text and outputing each line to a file.\n",
    "In parallel we create another file that is the json of the cleaned SRT so we can align the SRT timestamps with gentle's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "let RegexSplit (regex : System.Text.RegularExpressions.Regex)  (input:string) = regex.Split( input )\n",
    "\n",
    "let RegexReplace (regex : System.Text.RegularExpressions.Regex) (replacement:string) (input:string) =\n",
    "    regex.Replace( input, replacement )\n",
    "    \n",
    "let StringReplace (target:string) (replacement:string) (input:string) =\n",
    "    input.Replace(target, replacement)\n",
    "\n",
    "let StringTrim (inputString : string ) = inputString.Trim() \n",
    "    \n",
    "let whiteSpaceRegex = System.Text.RegularExpressions.Regex(\"\\s+\")\n",
    "let nonApostrophePunctRegex = System.Text.RegularExpressions.Regex(\"[^\\w\\s']\")\n",
    "let tagRegex = System.Text.RegularExpressions.Regex(\"<.*?>\") //only acceptable b/c our subtitle markup is so simplistic it does not require CFG parser\n",
    "let notLatinRegex = System.Text.RegularExpressions.Regex(\"[^\\p{IsBasicLatin}]\")\n",
    "let leadingNameRegex = System.Text.RegularExpressions.Regex( \"^\\s*[^: ]+:\" ) \n",
    "let descriptionRegex = System.Text.RegularExpressions.Regex( \"(\\[[^\\]]+\\]|\\([^\\)]+\\))\" ) \n",
    "let blankLinesRegex = new System.Text.RegularExpressions.Regex(\"\\n\\n+\")\n",
    "\n",
    "let CleanText (inputString : string ) =\n",
    "    inputString \n",
    "    //ocr errors\n",
    "    |> StringReplace \"|\" \"I\"\n",
    "    |> StringReplace \"-\" \" \"\n",
    "    //non-speakables and formatting\n",
    "    |> StringReplace \"\\\"\" \" \"\n",
    "    |> RegexReplace tagRegex \" \" \n",
    "    |> RegexReplace notLatinRegex \" \"     //removes quarter notes indicating song\n",
    "    |> RegexReplace leadingNameRegex \" \"  //removes name identifier\n",
    "    |> RegexReplace descriptionRegex \" \"  //removes e.g. [cough]\n",
    "    |> RegexReplace whiteSpaceRegex \" \" \n",
    "    |> StringTrim\n",
    "    //some punctuation has spaces before\n",
    "    |> StringReplace \" .\" \".\"\n",
    "    |> StringReplace \" ?\" \"?\"\n",
    "    |> StringReplace \" !\" \"!\" \n",
    "    \n",
    "type SrtSubtitle = { Start : int; Stop : int; Text : string }\n",
    "let SrtStringToTime( timeString ) =  System.TimeSpan.ParseExact(timeString, @\"hh\\:mm\\:ss\\,fff\", null).TotalMilliseconds\n",
    "let ReadSRT filePath = \n",
    "    ( filePath |> System.IO.File.ReadAllText).Trim() \n",
    "    |> RegexSplit blankLinesRegex \n",
    "    |> Array.map(fun block ->\n",
    "        let blockLines = block.Split('\\n')\n",
    "        //we assume blockLines.[0] is the id for the subtitle\n",
    "        let startEnd = blockLines.[1].Replace( \" --> \", \" \").Trim().Split(' ')\n",
    "        let start = startEnd.[0] |> SrtStringToTime |> int\n",
    "        let stop = startEnd.[1] |> SrtStringToTime |> int\n",
    "        let subtitle = blockLines |> Array.skip 2 |> String.concat \" \" |> CleanText\n",
    "        { Start = start;  Stop = stop ; Text = subtitle}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "#r \"/z/aolney/repos/Newtonsoft.Json.9.0.1/lib/net40/Newtonsoft.Json.dll\"\n",
    "//LOOP TO GENERATE GENTLE TRANSCRIPTS FOR ALL DISCS\n",
    "let dataDirectory = \"/y/south-park-1-to-20/\"\n",
    "for filePath in System.IO.Directory.GetFiles(dataDirectory, \"*.srt\")  do\n",
    "    let srtSubtitles = filePath |> ReadSRT\n",
    "    let validSubtitles = srtSubtitles |> Seq.filter( fun s -> s.Text <> \"\" )     //valid subtitles are nonempty\n",
    "    System.IO.File.WriteAllLines( filePath + \".transcript\", validSubtitles |> Seq.map( fun s -> s.Text ) )    //gentle transcript using valid subtitles\n",
    "    let validSrtJson = Newtonsoft.Json.JsonConvert.SerializeObject(validSubtitles,Newtonsoft.Json.Formatting.Indented)    //for later alignment of valid subtitle information with gentle output\n",
    "    System.IO.File.WriteAllText(filePath + \".validsub\",validSrtJson )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "ifsharp"
   },
   "source": [
    "### Run gentle\n",
    "\n",
    "Assumes docker has started container (run in a different terminal). Each disc takes about 45 minutes on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/y/south-park-1-to-20/\n",
      "/y/south-park-1-to-20/15-1.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211M    0 6382k  100  205M   2802  92292  0:38:52  0:38:52 --:--:-- 1667k\n",
      "/y/south-park-1-to-20/15-2.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  210M    0 5634k  100  205M   2520  93951  0:38:08  0:38:08 --:--:-- 1356k\n",
      "/y/south-park-1-to-20/15-3.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  168M    0 5047k  100  163M   2977  99028  0:28:55  0:28:55 --:--:-- 1031k\n",
      "/y/south-park-1-to-20/16-1.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  210M    0 5802k  100  205M   2516  91136  0:39:20  0:39:20 --:--:-- 1564k\n",
      "/y/south-park-1-to-20/16-2.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211M    0 6238k  100  205M   2817  94853  0:37:47  0:37:47 --:--:-- 1719k\n",
      "/y/south-park-1-to-20/16-3.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  168M    0 4829k  100  164M   2785  96875  0:29:35  0:29:35 --:--:-- 1109k\n",
      "/y/south-park-1-to-20/17-1.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211M    0 6550k  100  204M   3036  97273  0:36:49  0:36:49 --:--:-- 1477k\n",
      "/y/south-park-1-to-20/17-2.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  210M    0 6171k  100  204M   2827  96150  0:37:14  0:37:14 --:--:-- 1446k\n",
      "/y/south-park-1-to-20/18-1.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211M    0 6639k  100  204M   3021  95489  0:37:29  0:37:29 --:--:-- 1633k\n",
      "/y/south-park-1-to-20/18-2.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211M    0 6826k  100  204M   2905  89284  0:40:06  0:40:06 --:--:-- 1705k\n",
      "/y/south-park-1-to-20/19-1.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211M    0 6624k  100  204M   2908  92117  0:38:52  0:38:52 --:--:-- 1591k\n",
      "/y/south-park-1-to-20/19-2.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211M    0 6662k  100  204M   2985  93999  0:38:05  0:38:05 --:--:-- 1589k\n",
      "/y/south-park-1-to-20/20-1.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211M    0 6324k  100  204M   2971  98581  0:36:19  0:36:19 --:--:-- 1752k\n",
      "/y/south-park-1-to-20/20-2.wav\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  211M    0 6269k  100  204M   2877  96280  0:37:11  0:37:11 --:--:-- 1449k\n"
     ]
    }
   ],
   "source": [
    "#assumes that wav and srt are in the same directory\n",
    "directory=\"/y/south-park-1-to-20/\"\n",
    "echo $directory\n",
    "\n",
    "#Specific files (for restarts)\n",
    "#wavList=\"/y/south-park-1-to-20/1-1.wav /y/south-park-1-to-20/1-2.wav /y/south-park-1-to-20/1-3.wav /y/south-park-1-to-20/2-1.wav /y/south-park-1-to-20/2-2.wav /y/south-park-1-to-20/2-3.wav /y/south-park-1-to-20/3-1.wav /y/south-park-1-to-20/3-2.wav /y/south-park-1-to-20/3-3.wav /y/south-park-1-to-20/4-1.wav /y/south-park-1-to-20/4-2.wav /y/south-park-1-to-20/4-3.wav /y/south-park-1-to-20/5-1.wav /y/south-park-1-to-20/5-2.wav /y/south-park-1-to-20/5-3.wav /y/south-park-1-to-20/6-1.wav /y/south-park-1-to-20/6-2.wav /y/south-park-1-to-20/6-3.wav /y/south-park-1-to-20/7-1.wav /y/south-park-1-to-20/7-2.wav /y/south-park-1-to-20/7-3.wav /y/south-park-1-to-20/8-1.wav /y/south-park-1-to-20/8-2.wav /y/south-park-1-to-20/8-3.wav /y/south-park-1-to-20/9-1.wav /y/south-park-1-to-20/9-2.wav /y/south-park-1-to-20/9-3.wav /y/south-park-1-to-20/10-1.wav /y/south-park-1-to-20/10-2.wav /y/south-park-1-to-20/10-3.wav /y/south-park-1-to-20/11-1.wav /y/south-park-1-to-20/11-2.wav /y/south-park-1-to-20/11-3.wav /y/south-park-1-to-20/12-1.wav /y/south-park-1-to-20/12-2.wav /y/south-park-1-to-20/12-3.wav /y/south-park-1-to-20/13-1.wav /y/south-park-1-to-20/13-2.wav /y/south-park-1-to-20/13-3.wav /y/south-park-1-to-20/14-1.wav /y/south-park-1-to-20/14-2.wav /y/south-park-1-to-20/14-3.wav /y/south-park-1-to-20/15-1.wav /y/south-park-1-to-20/15-2.wav /y/south-park-1-to-20/15-3.wav /y/south-park-1-to-20/16-1.wav /y/south-park-1-to-20/16-2.wav /y/south-park-1-to-20/16-3.wav /y/south-park-1-to-20/17-1.wav /y/south-park-1-to-20/17-2.wav /y/south-park-1-to-20/18-1.wav /y/south-park-1-to-20/18-2.wav /y/south-park-1-to-20/19-1.wav /y/south-park-1-to-20/19-2.wav /y/south-park-1-to-20/20-1.wav /y/south-park-1-to-20/20-2.wav\"\n",
    "wavList=\"/y/south-park-1-to-20/15-1.wav /y/south-park-1-to-20/15-2.wav /y/south-park-1-to-20/15-3.wav /y/south-park-1-to-20/16-1.wav /y/south-park-1-to-20/16-2.wav /y/south-park-1-to-20/16-3.wav /y/south-park-1-to-20/17-1.wav /y/south-park-1-to-20/17-2.wav /y/south-park-1-to-20/18-1.wav /y/south-park-1-to-20/18-2.wav /y/south-park-1-to-20/19-1.wav /y/south-park-1-to-20/19-2.wav /y/south-park-1-to-20/20-1.wav /y/south-park-1-to-20/20-2.wav\"\n",
    "(\n",
    "for wav in ${wavList}; do\n",
    "    echo \"$wav\"\n",
    "    base=\"$(basename \"$wav\" .wav)\"\n",
    "    prefix=${base%-*}\n",
    "    if [ \"$prefix\" -gt \"14\" ]; then\n",
    "        curl -F \"audio=@/$wav\" -F \"transcript=@$directory${base}_track3.srt.transcript\" \"http://0.0.0.0:8765/transcriptions?async=false&disfluency=true&conservative=true\" -o \"$directory$base\".json\n",
    "    else\n",
    "        curl -F \"audio=@/$wav\" -F \"transcript=@$directory$base.srt.transcript\" \"http://0.0.0.0:8765/transcriptions?async=false&disfluency=true&conservative=true\" -o \"$directory$base\".json\n",
    "    fi\n",
    "    sleep 60; #because its nice to sleep\n",
    "done\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Align to transcripts for speaker identification \n",
    "\n",
    "**NOTE:** There was [an issue](https://github.com/dotnet/fsharp/issues/6833) running this code from Jupyter. Until this is resolved, the alternative is to copy/paste next several cells into a .fsx file and compile:\n",
    "```\n",
    "fsharpc --debug -r:/z/aolney/repos/Newtonsoft.Json.9.0.1/lib/net40/Newtonsoft.Json.dll doAlign.fsx \n",
    "```\n",
    "\n",
    "\n",
    "### Load Southpark transcript data (with speaker annotations)\n",
    "\n",
    "Transcript data is https://github.com/aolney/SouthParkTranscripts for seasons 1-20, which extends [BobAdamsEE/SouthParkData](https://github.com/BobAdamsEE/SouthParkData), which is in turn a cleaned version of [southpark.fandom](https://southpark.fandom.com/wiki/Portal:Scripts). \n",
    "These data sources list which character is speaking each line, so we can get speaker identification by aligning with these resources.\n",
    "We have resaved this as tab delimited to reduce the complexity of parsing CSV with commas embedded.\n",
    "We note that some episodes seem to have a different order than reported disc, so correct those below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "let transcriptFilePath = \"/y/south-park-1-to-20/SouthParkTranscripts/s1-20.tsv\"\n",
    "\n",
    "type TranscriptLine = \n",
    "    {\n",
    "        Season: int\n",
    "        Episode: int\n",
    "        Character: string\n",
    "        Line: string\n",
    "    }\n",
    "    override x.ToString() = x.Line\n",
    "\n",
    "//Parse into TranscriptLines\n",
    "let transcriptLines = \n",
    "    transcriptFilePath \n",
    "    |> System.IO.File.ReadAllLines\n",
    "    |> Seq.skip 1 //header\n",
    "    |> Seq.map(fun line ->\n",
    "                  let s = line.Split('\\t')\n",
    "                  let season = System.Int32.Parse(s.[0])\n",
    "                  let episode =\n",
    "                        match season,System.Int32.Parse(s.[1]) with\n",
    "                        //\"Volcano\" comes second on DVD but otherwise seems to be 3rd episode\n",
    "                        | 1,2 -> 3\n",
    "                        | 1,3 -> 2\n",
    "                        //Jakovasaurs and Tweak vs Craig are switched in transcripts\n",
    "                        | 3,4 -> 5 \n",
    "                        | 3,5 -> 4 \n",
    "                        //switched in transcripts\n",
    "                        | 3,10 -> 11 \n",
    "                        | 3,12 -> 10\n",
    "                        | 3,13 -> 12\n",
    "                        | 3,11 -> 13\n",
    "                        //switched in transcripts\n",
    "                        | 4,2 -> 1\n",
    "                        | 4,1 -> 2\n",
    "                        | 4,3 -> 4\n",
    "                        | 4,4 -> 3\n",
    "                        | 4,5 -> 14\n",
    "                        | 4,6 -> 5\n",
    "                        | 4,7 -> 6\n",
    "                        | 4,8 -> 7\n",
    "                        | 4,9 -> 8\n",
    "                        | 4,10 -> 9\n",
    "                        | 4,11 -> 10\n",
    "                        | 4,12 -> 11\n",
    "                        | 4,13 -> 12\n",
    "                        | 4,14 -> 13\n",
    "                        //switched in transcripts\n",
    "                        //| 6,4 -> 5\n",
    "                        //| 6,5 -> 4\n",
    "                        | _,j -> j\n",
    "                  {Season = season; Episode = episode; Character = s.[2]; Line = s.[3].Trim('\"')}\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "ifsharp"
   },
   "source": [
    "### Alignment functions for gentle subtitle data and transcripts\n",
    "\n",
    "We use edit distance to get alignment. \n",
    "The most complicated part is finding the subtitles that correspond to an episode in the transcripts. \n",
    "We use the theme song as a marker but this is tricky because some episodes don't have the song, and sometimes the subtitles for the song are incorrect.\n",
    "\n",
    "In most cases, it would probably be better to use chapter boundaries to do this work. \n",
    "As described above, this was less promising than using text for our particular case.\n",
    "\n",
    "Why edit distance? Surprisingly the transcripts and subtitles are fairly different, not just at the utterance level but also with larger text blocks like commentary and songs that are only in the subtitles. \n",
    "Segmenting out episodes of subtitles improves the edit distance alignment and also helps prevent out-of-memory problems.\n",
    "\n",
    "Here is an example of an alignment with discrepancies for transcript and subtitles even after garbage has been removed (top line is transcript, bottom line is subtitle, and bars indicate the boundary of a subtitle or transcript line):\n",
    "\n",
    "```\n",
    "*SCHOOL DAY* SCHOOL DAY** TEACHER'S GOLDEN RU|AH DAMN IT MY LITTLE BROTHER'S TRYING TO FOLLOW ME\n",
    " SCHOOL DAYS SCHOOL DAYS| DEAR OLD* GOLDEN***|GODDAMN IT MY LITTLE BROTHER'S|TRYING TO FOLLOW ME\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "//\"/z/aolney/repos/Newtonsoft.Json.12.0.2/lib/net45/Newtonsoft.Json.dll\"\n",
    "#r \"/z/aolney/repos/Newtonsoft.Json.9.0.1/lib/net40/Newtonsoft.Json.dll\"\n",
    "\n",
    "//Chapter constructs are unused as explained in the notes, but could represent the most useful way to do episode segmentation in other contexts, so leaving for future reference\n",
    "type Chapter =\n",
    "    {\n",
    "        id : int\n",
    "        time_base: string\n",
    "        start: int\n",
    "        start_time: float\n",
    "        ``end``: int\n",
    "        end_time: float\n",
    "        tags: Map<string,string>\n",
    "    }\n",
    "type DiscChapters =\n",
    "    {\n",
    "        chapters : Chapter[]\n",
    "    }\n",
    "\n",
    "//Gentle alignment structures\n",
    "//We intentionally ignore phonemes that are part of gentle's alignment output b/c we don't need them\n",
    "type Word =\n",
    "    {\n",
    "        case : string\n",
    "        //these only exist when case <> \"not-found-in-transcript\"\n",
    "        endOffset : int\n",
    "        startOffset : int\n",
    "        word : string\n",
    "        //these only exist when case is \"success\"\n",
    "        ///In seconds\n",
    "        start : float\n",
    "        ///In seconds\n",
    "        ``end`` : float\n",
    "\n",
    "    }\n",
    "    override x.ToString() = x.word + \"-\" + x.start.ToString()  + \":\" + x.``end``.ToString()\n",
    "\n",
    "type GentleAlignment =\n",
    "    {\n",
    "        transcript : string\n",
    "        words : Word[]\n",
    "    }\n",
    "\n",
    "//Legacy: we repackage gentle into the CCAligner structure below to avoid having to rewrite the complex alignment code.\n",
    "type Subtitle =\n",
    "    {\n",
    "        subtitle : string\n",
    "        edited_text : string\n",
    "        ///In milliseconds\n",
    "        start : int\n",
    "        ///In milliseconds\n",
    "        ``end`` : int\n",
    "        words : Word[] //extension for gentle\n",
    "    }\n",
    "    override x.ToString() = x.edited_text + \"-\" + x.start.ToString()  + \":\" + x.``end``.ToString()\n",
    "\n",
    "type CCAligned =\n",
    "    {\n",
    "        subtitles : Subtitle[]\n",
    "    }\n",
    " \n",
    "///Legacy: repackage gentle alignment into CCAligner structure to avoid having to rewrite the complex alignment code.\n",
    "let GentleToSubtitles filePath =\n",
    "    //gentle's output\n",
    "    let gentleJson = System.IO.File.ReadAllText( filePath )\n",
    "    let gentleAlignment = Newtonsoft.Json.JsonConvert.DeserializeObject<GentleAlignment>(gentleJson)\n",
    "    //we also need the SRT from which the transcript gentle used was derived; this has start/end boundaries for the subtitle (needed if gentle does not recognize a word)\n",
    "    let validSrtJson = \n",
    "        if System.IO.File.Exists( filePath.Replace(\".json\",\".srt.validsub\" ) ) then\n",
    "            System.IO.File.ReadAllText( filePath.Replace(\".json\",\".srt.validsub\" ) )\n",
    "        //vobsub\n",
    "        else\n",
    "            System.IO.File.ReadAllText( filePath.Replace(\".json\",\"_track3.srt.validsub\" ) )\n",
    "    let validSrt = Newtonsoft.Json.JsonConvert.DeserializeObject<SrtSubtitle[]>(validSrtJson)\n",
    "  \n",
    "    seq {\n",
    "        let mutable charStartIndex = 0\n",
    "        let mutable wordIndex = 0\n",
    "        let mutable subtitleIndex = 0\n",
    "        for charIndex = 0 to gentleAlignment.transcript.Length - 1 do\n",
    "            //subtitles are bounded by newline because when we generated transcripts for gentle from the SRT, we put a newline after each subtitle\n",
    "            //gentle uses character offsets, so we can accumulate words into a subtitle until we reach the appropriate offset\n",
    "            if gentleAlignment.transcript.[charIndex] = '\\n' then\n",
    "                let words = \n",
    "                    [|\n",
    "                        while wordIndex < gentleAlignment.words.Length && gentleAlignment.words.[wordIndex].endOffset <= charIndex do\n",
    "                            yield gentleAlignment.words.[wordIndex]\n",
    "                            wordIndex <- wordIndex + 1\n",
    "                    |] \n",
    "                \n",
    "                //subtitle has whatever formatting got through to gentle\n",
    "                let subtitle = gentleAlignment.transcript.Substring(charStartIndex,charIndex-charStartIndex)\n",
    "                //edited text has whatever formatting gentle did not strip out, plus filler words not in transcript\n",
    "                let edited_text = words |> Array.map( fun w -> w.word ) |> String.concat \" \"\n",
    "                charStartIndex <- charIndex + 1\n",
    "\n",
    "                if validSrt.[subtitleIndex].Text <> subtitle then failwith \"mismatch between gentle transcript subtitle and srt subtitle\"\n",
    "                yield { subtitle=subtitle; edited_text=edited_text; start=validSrt.[subtitleIndex].Start; ``end``=validSrt.[subtitleIndex].Stop; words=words |> Seq.toArray }\n",
    "                subtitleIndex <- subtitleIndex + 1\n",
    "    }\n",
    "   \n",
    "\n",
    "type Alignment =\n",
    "    {\n",
    "        Season: int\n",
    "        Episode: int\n",
    "        Disc: int\n",
    "        Character: string\n",
    "        Turn: string //can contain multiple utterances\n",
    "        TurnIndex : int\n",
    "        Subtitles : Subtitle[]\n",
    "    }\n",
    "    override x.ToString() = x.Turn\n",
    "\n",
    "type TTSData =\n",
    "    {\n",
    "        Start : int\n",
    "        Stop : int\n",
    "        Text : string\n",
    "        Id : string\n",
    "    }\n",
    "    \n",
    "//http://www.fssnip.net/bc/title/EditDistance\n",
    "//modified for memory reasons\n",
    "type DistanceType = MinimumEditDistance | LevenshteinDistance\n",
    "\n",
    "let getEditDistance distanceType (X:string) (Y:string) =\n",
    "    let m = X.Length\n",
    "    let n = Y.Length\n",
    "    let d = Array2D.init (m + 1) (n + 1) (fun i j -> if j = 0 then i elif i = 0 then j else 0)\n",
    "    let ptr = //System.Collections.Generic.Dictionary<string,char>()// \n",
    "        Array2D.init (m + 1) (n + 1) (fun i j -> if j = 0 then 'd' elif i = 0 then 'i' else 's')\n",
    "    //let ptr = Array2D.init (m + 1) (n + 1) (fun i j -> if j = 0 then Deletion elif i = 0 then Insertion else Substitution)\n",
    "    let penalizationForSubstitution = \n",
    "        match distanceType with\n",
    "        | MinimumEditDistance -> 1\n",
    "        | LevenshteinDistance -> 2\n",
    "    for i in 1..m do\n",
    "        for j in 1..n do\n",
    "            let a, b = Seq.minBy fst [d.[i-1, j] + 1, 'd' //Deletion\n",
    "                                      d.[i, j-1] + 1, 'i' //Insertion\n",
    "                                      d.[i-1, j-1] + (if X.[i-1] <> Y.[j-1] then penalizationForSubstitution else 0), 's'] //Substitution]\n",
    "            d.[i, j] <- a\n",
    "            ptr.[i, j] <- b\n",
    "    let alignment = \n",
    "        (m, n) \n",
    "        |> Seq.unfold (fun (i, j) -> \n",
    "            if i = 0 && j = 0 then\n",
    "                None\n",
    "            else\n",
    "                match ptr.[i, j] with\n",
    "                | 'd' -> Some((X.[i-1], '*'), (i-1, j))\n",
    "                | 'i' -> Some(('*', Y.[j-1]), (i, j-1))\n",
    "                | 's' -> Some((X.[i-1], Y.[j-1]), (i-1, j-1)) //)\n",
    "                | _ -> None )\n",
    "        |> Array.ofSeq\n",
    "        |> Array.rev\n",
    "    d.[m, n], alignment\n",
    "\n",
    "let printAlignment alignment season episode directory = \n",
    "    let toString (chars : char array) = new string(chars)\n",
    "    System.IO.File.WriteAllText( directory + season.ToString() + \"-\" + episode.ToString() + \".editalignment\", (alignment |> Array.map fst |> toString) + \"\\n\" + (alignment |> Array.map snd |> toString) ) \n",
    "\n",
    "\n",
    "///Return a sequence of episode subtitle sequences that approximately match transcripts (no theme song, no DVD special introduction)\n",
    "let GetCleanEpisodeSubtitles ( subtitleLines : Subtitle[] ) subtitleSeason = //(transcriptNormLines : seq<TranscriptLine>) \n",
    "\n",
    "    //First line of song has inconsistent subtitles; \n",
    "    //using the second line GONNA HAVE MYSELF A TIME; \n",
    "    //\"Monkey Phonics\" missing that so changed to \"FRIENDLY FACES EVERYWHERE\"\n",
    "    //s6-e1 missing so changed to \"HUMBLE FOLKS WITHOUT TEMPTATION\"\n",
    "    //S1-E9 has no song, using THE CHRISTMAS CHOCOLATE BAR\n",
    "    //S2-E1 has no song, using WHAT A BRILLIANT PIECE OF WORK IT IS\n",
    "    //S3-E13 has no song, using THIS IS MARKLAR\n",
    "    //S3-E15 has no song, using ALL HEARD OF RUDOLPH AND HIS SHINY NOSE\n",
    "    //S4-E10 has no song, using TODAY WE ARE GOING TO TALK ABOUT HELL //everyone in this town ourselves\n",
    "    //s4-e14 has no song, using AHH DICKENS / THE IMAGERY OF COBBLESTONE STREETS\n",
    "    //s5-e14 has not song, using ALL DONE WRAPPING DAD'S ANNIVERSARY PRESENT\n",
    "    //S6-E2 has no song, using THANKS FOR HAVING US ALL OVER FOR DINNER CHRIS AND LINDA\n",
    "    //s6-e4 has no MEET SOME FRIENDS OF MINE changed to SO COME ON DOWN TO SOUTH PARK\n",
    "    //17-E8 has no song OF THE MEN LADY MCKORMICK / YOU CANT DIEL\n",
    "    //17-e9 has alt song Yes | think that will do nicely / f Flopping wieners flopping wieners I\n",
    "    //let songStartRegex = new System.Text.RegularExpressions.Regex( \"THANKS FOR HAVING US ALL OVER FOR DINNER CHRIS AND LINDA|HUMBLE FOLKS WITHOUT TEMPTATION|AHH DICKENS|TODAY WE ARE GOING TO TALK ABOUT HELL|ALL HEARD OF RUDOLPH AND HIS SHINY NOSE|THIS IS MARKLAR|THE CHRISTMAS CHOCOLATE BAR|WHAT A BRILLIANT PIECE OF WORK IT IS\", System.Text.RegularExpressions.RegexOptions.IgnoreCase )\n",
    "    //let songEndRegex = new System.Text.RegularExpressions.Regex( \"SO COME ON DOWN TO SOUTH PARK|YES IT WAS FABULOUS|THE IMAGERY OF COBBLESTONE STREETS|EVERYONE IN THIS TOWN OURSELVES|ALL HEARD OF RUDOLPH AND HIS SHINY NOSE|THIS IS MARKLAR|THE CHRISTMAS CHOCOLATE BAR|WHAT A BRILLIANT PIECE OF WORK IT IS\", System.Text.RegularExpressions.RegexOptions.IgnoreCase )\n",
    "    let songStartRegex = new System.Text.RegularExpressions.Regex( \"GO[^D]+DOWN TO SOUTH PARK|HAVE MYSELF A[ ]?TIME|FRIENDLY FACES EVERYWHERE|HUMBLE FOLKS WITHOUT TEMPTATION|DEATH AND SADNESS EVERYWHERE|LONELINESS AND DEGRADATION\", System.Text.RegularExpressions.RegexOptions.IgnoreCase )\n",
    "    let altStartRegex = new System.Text.RegularExpressions.Regex( \"ALL DONE WRAPPING DAD'S ANNIVERSARY PRESENT|THINK THAT WILL DO NICELY|OF THE MEN LADY MCKORMICK|THANKS FOR HAVING US ALL OVER FOR DINNER CHRIS AND LINDA|AHH DICKENS|TODAY WE ARE GOING TO TALK ABOUT HELL|ALL HEARD OF RUDOLPH AND HIS SHINY NOSE|THIS IS MARKLAR|THE CHRISTMAS CHOCOLATE BAR|WHAT A BRILLIANT PIECE OF WORK IT IS\", System.Text.RegularExpressions.RegexOptions.IgnoreCase )\n",
    "    let songEndRegex = new System.Text.RegularExpressions.Regex( \"LEAVE MY WOES BEHIND|AMPLE PARKING DAY OR[ ]?NIGHT|SPOUTING HOWDY NEIGHBOR|SEE IF I CAN'T[ ]?UNWIND|COME ON DOWN TO SOUTH PARK|MEET SOME FRIENDS OF MINE|POSERS SPOUTING LET'S GO SHOPPING|TO DIE TO DIE\", System.Text.RegularExpressions.RegexOptions.IgnoreCase )\n",
    "    let altEndRegex = new System.Text.RegularExpressions.Regex( \"OH IS IT SOMEONE'S ANNIVERSARY SOON|J NONERECT WIENERS J|YOU CANT DIEL|YES IT WAS FABULOUS|THE IMAGERY OF COBBLESTONE STREETS|EVERYONE IN THIS TOWN OURSELVES|ALL HEARD OF RUDOLPH AND HIS SHINY NOSE|THIS IS MARKLAR|THE CHRISTMAS CHOCOLATE BAR|WHAT A BRILLIANT PIECE OF WORK IT IS\", System.Text.RegularExpressions.RegexOptions.IgnoreCase )\n",
    "\n",
    "    //Get the song start subtitle and index by season/episode\n",
    "    // PROBLEM: very commonly subtitles are missing for any given part of the song we might select\n",
    "    // so we look for multiple lines but then only choose one at either the beginning or end (using firstLast function)\n",
    "    let GetSongBoundarySubtitleMap (songRegex : System.Text.RegularExpressions.Regex ) (altRegex :System.Text.RegularExpressions.Regex) firstLast subLines = \n",
    "        seq {\n",
    "            //first use the song. This implicitly requires multiple song matches\n",
    "            let threshold = 10000 //no more than 10 seconds between song subtitles\n",
    "            let candidateTuples = \n",
    "                subLines\n",
    "                |> Seq.choose( fun s -> if songRegex.IsMatch( s.edited_text ) || songRegex.IsMatch( s.subtitle )  then Some(s) else None )\n",
    "                |> Seq.pairwise\n",
    "                |> Seq.map( fun (s1,s2) -> if s2.start - s1.``end`` < threshold then (s1,true) else (s2,false)  ) //calculate gap, make sure its < 10 sec\n",
    "                //|> Seq.sortBy( fun (s,bool) -> (s.start,bool|>not) )\n",
    "                |> ResizeArray\n",
    "            //let debugCopy = candidateTuples.ToArray()\n",
    "            //for unknown reasons, sometimes the first element is false\n",
    "            if candidateTuples.[0] |> snd = false then\n",
    "                candidateTuples.RemoveAt(0)\n",
    "            while candidateTuples.Count > 0 do\n",
    "                let song = candidateTuples |> Seq.toArray |> Array.takeWhile snd //true means close\n",
    "                if song.Length = 0 then \n",
    "                    failwith \"Possible missing song\"\n",
    "                let debugYield = song |> firstLast |> fst \n",
    "                yield debugYield\n",
    "                candidateTuples.RemoveRange(0, song.Length )\n",
    "                let gap = candidateTuples |> Seq.toArray |> Array.takeWhile( snd >> not )  //false means a gap\n",
    "                candidateTuples.RemoveRange(0, gap.Length )\n",
    "            //now use alternative matches. Only one match is required\n",
    "            for alt in subLines |> Seq.choose( fun s -> if altRegex.IsMatch( s.edited_text ) ||  altRegex.IsMatch( s.subtitle )  then Some(s) else None ) do\n",
    "                yield alt\n",
    "        }\n",
    "        |> Seq.sortBy( fun s -> s.start ) //sorting needed b/c our alt matches came in a second traversal\n",
    "        |> Seq.mapi( fun i s -> (subtitleSeason, i + 1), s )\n",
    "        |> Map.ofSeq\n",
    "\n",
    "    let songStartSubtitleMap = subtitleLines |> GetSongBoundarySubtitleMap songStartRegex altStartRegex Array.head\n",
    "    let songEndSubtitleMap = subtitleLines |> GetSongBoundarySubtitleMap songEndRegex altEndRegex Array.last\n",
    "\n",
    "        \n",
    "    //From the possible last subtitles find the subtitle that comes right before the following song\n",
    "    let lastSubtitleMap =\n",
    "        songStartSubtitleMap\n",
    "        |> Seq.choose( fun (KeyValue((season,episode),songStartSubtitle)) -> \n",
    "            let preceedingPossibleLastSubtitles =\n",
    "                //original gap approach\n",
    "                //possibleLastSubtitles\n",
    "                //|> Seq.map fst\n",
    "                //end original gap approach\n",
    "                subtitleLines\n",
    "                //remove bogus captioning subtitles\n",
    "                |> Seq.filter( fun s -> s.subtitle.Contains(\"CAPTIONED\") |> not )\n",
    "                |> Seq.filter( fun pls -> pls.``end`` < songStartSubtitle.start )\n",
    "            if preceedingPossibleLastSubtitles |> Seq.isEmpty then\n",
    "                None\n",
    "            else\n",
    "                Some( (season,episode), preceedingPossibleLastSubtitles |> Seq.maxBy( fun subtitle -> subtitle.``end`` ) )\n",
    "            )\n",
    "        |> Map.ofSeq\n",
    "       \n",
    "    let NotToLastSubtitleBeforeNextSong season episode subtitle =\n",
    "        match lastSubtitleMap.TryFind(season,episode + 1) with\n",
    "        | Some(lastSubtitle) -> subtitle.``end`` <= lastSubtitle.``end``  \n",
    "        | _ -> true //assumes no commetary after final episode on disc\n",
    "\n",
    "    //yield all subtitles bounded by the end of the song to the possible last subtitle that comes before the beginning of the next song\n",
    "    seq {\n",
    "        let mutable episode = 1\n",
    "        let mutable si = 0\n",
    "        let mutable notDone = true\n",
    "        let mutable notSongDone = true\n",
    "        while notDone do\n",
    "            //seek to end of song\n",
    "            while si < subtitleLines.Length && subtitleLines.[si] <> songEndSubtitleMap.[(subtitleSeason,episode)] do //(songEndRegex.IsMatch(subtitleLines.[si].edited_text) |> not) do\n",
    "            //while si < subtitleLines.Length && (subtitleLines.[si].edited_text.Contains(\"MEET SOME FRIENDS OF MINE\") |> not ) do\n",
    "                si <- si + 1\n",
    "            si <- si + 1\n",
    "            // yield until the last transcript match before the start of the next song\n",
    "            yield seq {\n",
    "                while si < subtitleLines.Length && NotToLastSubtitleBeforeNextSong subtitleSeason episode subtitleLines.[si] do\n",
    "                    yield subtitleLines.[si]\n",
    "                    si <- si + 1\n",
    "                si <- si + 1\n",
    "                //if si < subtitleLines.Length then yield subtitleLines.[si]\n",
    "            } |> Seq.toArray\n",
    "            episode <- episode + 1\n",
    "            if si >= subtitleLines.Length then\n",
    "                notDone <- false\n",
    "    } |> Seq.toArray\n",
    "\n",
    "//-------------------------------------------------------------------------------\n",
    "\n",
    "let RemovePunctuation inputString =\n",
    "    whiteSpaceRegex.Replace( nonApostrophePunctRegex.Replace( inputString, \" \"), \" \" ).Trim()\n",
    "let RemoveTags inputString =\n",
    "    whiteSpaceRegex.Replace( tagRegex.Replace( inputString, \" \"), \" \" ).Trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "ifsharp"
   },
   "source": [
    "### Align Subtitle and Transcript\n",
    "\n",
    "Because the actual edit distance alignment is very time consuming, it is sensible to calculate a first pass that fakes this part just to make sure that episodes are properly aligned between the transcripts and subtitles.\n",
    "Once this is confirmed, a real run with edit distance can be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "//LOOP TO DO ALIGNMENT FOR ALL DISCS\n",
    "let dataDirectory = \"/y/south-park-1-to-20/\"\n",
    "let alignedJsonFiles =\n",
    "    System.IO.Directory.GetFiles(dataDirectory, \"*.json\") \n",
    "    |> Seq.map( fun filePath ->\n",
    "        let seasonDiscSplit = System.IO.Path.GetFileNameWithoutExtension(filePath).Split('-')\n",
    "        let season = seasonDiscSplit.[0] |> System.Int32.Parse\n",
    "        let disc = seasonDiscSplit.[1] |> System.Int32.Parse\n",
    "        (season,disc),filePath )\n",
    "    |> Seq.sortBy fst\n",
    "    // !!!!!!!!!!!!!!!!!!!\n",
    "    //TODO: FOR DEBUG ONLY\n",
    "    // !!!!!!!!!!!!!!!!!!!\n",
    "    //|> Seq.filter(fun ((season,_),_) -> season > 16 && season < 18 ) //season > 16 )\n",
    "\n",
    "let editDistances = ResizeArray<string>() //output to Jupyter for error checking\n",
    "let mutable episodeOffset = 0 //we need to increment episodes across discs\n",
    "let mutable currentSeason = 0 //we need to reset episode offset at each season\n",
    "\n",
    "for (season,disc),filePath in alignedJsonFiles do\n",
    "//let parallelOptions = new System.Threading.Tasks.ParallelOptions()\n",
    "//parallelOptions.MaxDegreeOfParallelism <- 2\n",
    "//System.Threading.Tasks.Parallel.ForEach( ccAlignedJsonFiles, parallelOptions,  fun ((season,_),filePath) ->\n",
    "\n",
    "    if season <> currentSeason then\n",
    "        currentSeason <- season\n",
    "        episodeOffset <- 0\n",
    "\n",
    "    let sLines = filePath |> GentleToSubtitles |> Seq.toArray\n",
    "\n",
    "    // !!!!!!!!!!!!!!!!!!!\n",
    "    //TODO: FOR DEBUG ONLY\n",
    "    // !!!!!!!!!!!!!!!!!!!\n",
    "    //if season = 5 && episodeOffset >= 6 then\n",
    "    //    System.Console.WriteLine() \n",
    "\n",
    "    let episodeSubtitles = GetCleanEpisodeSubtitles sLines season\n",
    "\n",
    "    let alignments = ResizeArray<Alignment>()\n",
    "\n",
    "    episodeSubtitles\n",
    "    |> Seq.iteri (fun i episodeSubtitles ->\n",
    "\n",
    "        let episodeTranscriptLines = \n",
    "            transcriptLines\n",
    "            |> Seq.filter( fun tl -> tl.Season = season && tl.Episode = i + 1 + episodeOffset)\n",
    "            |> Seq.toArray\n",
    "\n",
    "        //create structured strings for edit distance alignment; replace pipes introduced by OCR\n",
    "        let tString = \n",
    "            episodeTranscriptLines\n",
    "            |> Array.map( fun tl -> tl.Line.Replace(\".\",\"\").Replace(\",\",\"\").Replace(\"!\",\"\").ToUpper().Replace(\"|\",\"I\" ) )\n",
    "            |> String.concat \"|\"\n",
    "\n",
    "        let sString =\n",
    "            episodeSubtitles\n",
    "            |> Seq.map( fun s -> s.subtitle.ToUpper().Replace(\"|\",\"I\" ) )\n",
    "            |> Seq.toArray\n",
    "            |> String.concat \"|\"\n",
    "\n",
    "        //perform edit distance alignment, save results\n",
    "        // !!!!!!!!!!!!!!!!!!!\n",
    "        //TODO: FOR DEBUG ONLY\n",
    "        // !!!!!!!!!!!!!!!!!!!\n",
    "        //let distanceM = 0\n",
    "        //let alignmentM = Array.zip (tString.ToCharArray().[0..500]) (sString.ToCharArray().[0..500])\n",
    "        //commenting out for loading files to avoid edit distance recalculation\n",
    "        //let alignmentSplit = System.IO.File.ReadAllText( dataDirectory + season.ToString() + \"-\" + (i+1+episodeOffset).ToString() + \".editalignment\" ).Split('\\n')\n",
    "        //let alignmentM = Array.zip (alignmentSplit.[0].ToCharArray()) (alignmentSplit.[1].ToCharArray())\n",
    "        //normal operation\n",
    "        let distanceM, alignmentM = getEditDistance MinimumEditDistance tString sString \n",
    "        printAlignment alignmentM season (i + 1 + episodeOffset) dataDirectory\n",
    "        //editDistances.Add( season.ToString() + \"-\" + (i + 1 + episodeOffset).ToString() + \": \" + distanceM.ToString() )\n",
    "\n",
    "        //walk the aligned strings to create an aligned object\n",
    "        let mutable mi = 0\n",
    "        let mutable matches = 0\n",
    "        let mutable si = 0\n",
    "        let mutable ti = 0\n",
    "        let tempSubtitles = ResizeArray<Subtitle>()\n",
    "        for tchar,uchar in alignmentM do\n",
    "            //matches means non insertions now\n",
    "            if uchar <> '*' && tchar <> '*' then\n",
    "                matches <- matches + 1\n",
    "            mi <- mi + 1\n",
    "            if uchar = '|' && si < episodeSubtitles.Length then\n",
    "                //avoid bad matches at beginning and end (e.g. song we couldn't clear); require some proportion are matched\n",
    "                if matches > mi / 3 then\n",
    "                    tempSubtitles.Add( episodeSubtitles.[si] )\n",
    "                matches <- 0\n",
    "                mi <- 0\n",
    "                si <- si + 1\n",
    "            if tchar = '|' && ti < episodeTranscriptLines.Length then \n",
    "                alignments.Add( \n",
    "                    {\n",
    "                    Season=episodeTranscriptLines.[ti].Season; \n",
    "                    Disc=disc\n",
    "                    Episode=i+1+episodeOffset; \n",
    "                    Character=episodeTranscriptLines.[ti].Character;\n",
    "                    Turn= episodeTranscriptLines.[ti].Line ;\n",
    "                    TurnIndex = ti;\n",
    "                    Subtitles = tempSubtitles.ToArray()\n",
    "                    } )\n",
    "                tempSubtitles.Clear()\n",
    "                ti <- ti + 1\n",
    "        )\n",
    "\n",
    "    let alignedJson = Newtonsoft.Json.JsonConvert.SerializeObject(alignments,Newtonsoft.Json.Formatting.Indented)\n",
    "    System.IO.File.WriteAllText(filePath + \".aligned\",alignedJson )\n",
    "    episodeOffset <- episodeOffset + episodeSubtitles.Length\n",
    "    //) |> ignore //parallel foreach\n",
    "//editDistances //for Jupyter output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "ifsharp"
   },
   "source": [
    "### Get LJSpeech format data for a specific character\n",
    "\n",
    "- Filter the alignments by character name\n",
    "- Group the subtitles by continuous speech (no gaps)\n",
    "    - Since longs strings cause CUDA OOM and have [unfavorable properties for deep learning](https://github.com/mozilla/TTS/wiki/Dataset), we further split by clause final punctuation and commas when continuous speech gets long\n",
    "- Clean nonspeech and junk from subtitles, including transformation of numerics to words\n",
    "- Output LJSpeech friendly segsox script and metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "#r \"/z/aolney/repos/Newtonsoft.Json.9.0.1/lib/net40/Newtonsoft.Json.dll\"\n",
    "\n",
    "let character = [|\"Eric\";\"Cartman\";\"Eric Cartman\"|]\n",
    "\n",
    "let alignmentDirectory = \"/y/south-park-1-to-20/gentle-discon/\" //\"/y/south-park-1-to-20/052519/\"\n",
    "let wavDirectory = \"/y/south-park-1-to-20/\"\n",
    "\n",
    "//NOTE: these are repeated definitions from earlier cells\n",
    "type Word =\n",
    "    {\n",
    "        case : string\n",
    "        //these only exist when case <> \"not-found-in-transcript\"\n",
    "        endOffset : int\n",
    "        startOffset : int\n",
    "        word : string\n",
    "        //these only exist when case is \"success\"\n",
    "        ///In seconds\n",
    "        start : float\n",
    "        ///In seconds\n",
    "        ``end`` : float\n",
    "\n",
    "    }\n",
    "    override x.ToString() = x.word + \"-\" + x.start.ToString()  + \":\" + x.``end``.ToString()\n",
    "\n",
    "type Subtitle =\n",
    "    {\n",
    "        subtitle : string\n",
    "        edited_text : string\n",
    "        ///In milliseconds\n",
    "        start : int\n",
    "        ///In milliseconds\n",
    "        ``end`` : int\n",
    "        words : Word[] //extension for gentle\n",
    "    }\n",
    "    override x.ToString() = x.edited_text + \"-\" + x.start.ToString()  + \":\" + x.``end``.ToString()\n",
    "\n",
    "type Alignment =\n",
    "    {\n",
    "        Season: int\n",
    "        Episode: int\n",
    "        Disc: int\n",
    "        Character: string\n",
    "        Turn: string //can contain multiple utterances\n",
    "        TurnIndex : int\n",
    "        Subtitles : Subtitle[]\n",
    "    }\n",
    "    override x.ToString() = x.Turn\n",
    "\n",
    "type TTSData =\n",
    "    {\n",
    "        Start : int\n",
    "        Stop : int\n",
    "        Text : string\n",
    "        Id : string\n",
    "        WavFile : string\n",
    "        FrontAligned : bool\n",
    "        EndAligned : bool\n",
    "    }\n",
    "    \n",
    "let RegexSplit (regex : System.Text.RegularExpressions.Regex)  (input:string) = regex.Split( input )\n",
    "\n",
    "let RegexReplace (regex : System.Text.RegularExpressions.Regex) (replacement:string) (input:string) =\n",
    "    regex.Replace( input, replacement )\n",
    "    \n",
    "let StringReplace (target:string) (replacement:string) (input:string) =\n",
    "    input.Replace(target, replacement)\n",
    "\n",
    "let StringTrim (inputString : string ) = inputString.Trim() \n",
    "    \n",
    "let whiteSpaceRegex = System.Text.RegularExpressions.Regex(\"\\s+\")\n",
    "let nonApostrophePunctRegex = System.Text.RegularExpressions.Regex(\"[^\\w\\s']\")\n",
    "let tagRegex = System.Text.RegularExpressions.Regex(\"<.*?>\") //only acceptable b/c our subtitle markup is so simplistic it does not require CFG parser\n",
    "let notLatinRegex = System.Text.RegularExpressions.Regex(\"[^\\p{IsBasicLatin}]\")\n",
    "let leadingNameRegex = System.Text.RegularExpressions.Regex( \"^\\s*[^:]+\\s*:\" ) \n",
    "let descriptionRegex = System.Text.RegularExpressions.Regex( \"(\\[[^\\]]+\\]|\\([^\\)]+\\))\" ) \n",
    "let blankLinesRegex = new System.Text.RegularExpressions.Regex(\"\\n\\n+\")\n",
    "\n",
    "let CleanText (inputString : string ) =\n",
    "    inputString \n",
    "    //ocr errors\n",
    "    |> StringReplace \"|\" \"I\"\n",
    "    |> StringReplace \"-\" \" \"\n",
    "    //non-speakables and formatting\n",
    "    |> StringReplace \"\\\"\" \" \"\n",
    "    |> RegexReplace tagRegex \" \" \n",
    "    |> RegexReplace notLatinRegex \" \"     //removes quarter notes indicating song\n",
    "    |> RegexReplace leadingNameRegex \" \"  //removes name identifier\n",
    "    |> RegexReplace descriptionRegex \" \"  //removes e.g. [cough]\n",
    "    |> RegexReplace whiteSpaceRegex \" \" \n",
    "    |> StringTrim\n",
    "    //some punctuation has spaces before\n",
    "    |> StringReplace \" .\" \".\"\n",
    "    |> StringReplace \" ?\" \"?\"\n",
    "    |> StringReplace \" !\" \"!\" \n",
    "\n",
    "//end repeated definitions\n",
    "\n",
    "//NOTE: includes comma\n",
    "let clauseFinalPunct = System.Text.RegularExpressions.Regex( \"\\s*[\\.\\?!,]+\\s*$\" ) \n",
    "//let leadingNameRegex = System.Text.RegularExpressions.Regex( \"(\" + character.[0] + \"\\s*:|\" + character.[1] + \"\\s*:|\" + character.[0].ToUpper() + \"\\s*:|\" + character.[1].ToUpper() + \"\\s*:)\" ) \n",
    "let IsClauseFinalPunct inputString =\n",
    "    clauseFinalPunct.IsMatch(inputString |> RegexReplace tagRegex \" \" )\n",
    "\n",
    "//utility functions for turning alignments into wav file scripts and metadata\n",
    "let GetWavFilename season disc =\n",
    "    season.ToString() + \"-\" + disc.ToString() + \".wav\"\n",
    "\n",
    "///Combine continguous subtitles into TTSData, noting where subtitle timings agree with alignment timings\n",
    "let MakeTTSData season disc (tlist: ResizeArray<Subtitle>) = \n",
    "    let threshold = 1000 //millisecond gap accepted between subtitle and alignment timings\n",
    "    //If alignment exists and somewhat agrees with subtitle, then we trust it's timing\n",
    "    //otherwise trust the subtitle timing\n",
    "    let firstWordStart = tlist.[0].words.[0].start * 1000.00 |> int\n",
    "    let start,frontAligned = \n",
    "        if tlist.[0].words.[0].case = \"success\" && System.Math.Abs( firstWordStart - tlist.[0].start) < threshold then\n",
    "            firstWordStart,true\n",
    "        else\n",
    "            tlist.[0].start,false\n",
    "    let lastWordStop = (tlist.[tlist.Count-1].words |> Array.last ).``end`` * 1000.00 |> int\n",
    "    let stop,endAligned = \n",
    "        if (tlist.[tlist.Count-1].words |> Array.last).case = \"success\" && System.Math.Abs( lastWordStop - tlist.[tlist.Count-1].``end``) < threshold then\n",
    "            lastWordStop,true\n",
    "        else\n",
    "            tlist.[tlist.Count-1].``end``,false\n",
    "    let sentence = tlist |> Seq.map( fun s -> s.subtitle ) |> String.concat \" \" |> RegexReplace tagRegex \" \" |> RegexReplace whiteSpaceRegex \" \" |> StringTrim\n",
    "    let id = character.[1] + \"-\" + season.ToString() + \"-\" + disc.ToString() + \"-\" + start.ToString() + \"-\" + stop.ToString()  \n",
    "    { Start=start; Stop=stop; Text=sentence; Id=id; WavFile = (GetWavFilename season disc); FrontAligned=frontAligned; EndAligned=endAligned}\n",
    "    \n",
    "let FormatTimeSox( record : TTSData ) =\n",
    "    let blankTime = new System.DateTime();\n",
    "    let startTime = blankTime.AddMilliseconds(record.Start |> float).ToString(\"HH:mm:ss.fff\");\n",
    "    let endTime = blankTime.AddMilliseconds(record.Stop |> float).ToString(\"HH:mm:ss.fff\");\n",
    "    //\n",
    "    startTime + \" =\" + endTime //an absolute end location can be given by preceding it with an equals sign\n",
    "\n",
    "let CreateSoxSegmentScript wavDirectory ( records : seq<TTSData>)  =\n",
    "    let soxCommands = records |> Seq.map( fun r -> \"sox \" + r.WavFile + \" wavs/\" + r.Id + \".wav trim \" + FormatTimeSox(r))\n",
    "    //let mkdirCommand = [ \"rm -rf wavs\"; \"mkdir wavs\"] |> Seq.ofList //clear out existing wav directory\n",
    "    let mkdirCommand = [ \"mkdir -p wavs\"] |> Seq.ofList //clear out existing wav directory\n",
    "    System.IO.File.WriteAllText(wavDirectory + \"segsox.sh\", String.concat \"\\n\" (Seq.append mkdirCommand  soxCommands) )\n",
    "\n",
    "// adapted with love from https://github.com/robertgreiner/NumberText/blob/master/NumberText/NumberText.cs\n",
    "let numberMap = [(0, \"zero\"); (1, \"one\"); (2, \"two\"); (3, \"three\"); (4, \"four\"); (5, \"five\"); (6, \"six\"); (7, \"seven\"); (8, \"eight\"); (9, \"nine\"); (10, \"ten\"); (11, \"eleven\"); (12, \"twelve\"); (13, \"thirteen\"); (14, \"fourteen\"); (15, \"fifteen\"); (16, \"sixteen\"); (17, \"seventeen\"); (18, \"eighteen\"); (19, \"nineteen\"); (20, \"twenty\"); (30, \"thirty\"); (40, \"forty\"); (50, \"fifty\"); (60, \"sixty\"); (70, \"seventy\"); (80, \"eighty\"); (90, \"ninety\"); (100, \"hundred\") ] |> Map.ofList\n",
    "let scales = [(1000000000.0, \"billion\"); (1000000.0, \"million\");  (1000.0, \"thousand\")] \n",
    "/// Convert integers to word equivalents\n",
    "let NumbersToText initialNumber =\n",
    "    let HundredsText num =\n",
    "        let mutable temp = num\n",
    "        let mutable hundredsText,tensText,unitText = \"\",\"\",\"\"\n",
    "        if temp > 99.0 then\n",
    "            let hundreds = temp/100.0 |> floor \n",
    "            hundredsText <- numberMap.[hundreds|> int] + \" hundred\"\n",
    "            temp <- temp - (hundreds * 100.0)\n",
    "        if temp > 20.0 then\n",
    "            let tens = (temp/10.0 |> floor) * 10.0\n",
    "            tensText <- numberMap.[tens|> int] \n",
    "            temp <- temp - tens\n",
    "        if temp > 0.0 then\n",
    "            unitText <- numberMap.[temp|> int] \n",
    "            temp <- 0.0\n",
    "        (hundredsText + \" \" + tensText + \" \" + unitText).Trim()\n",
    "            \n",
    "    let DoScale (scale:float,scaleWord:string ) (num:float, text:string) =\n",
    "        if num > scale - 1.0 then\n",
    "            let hundreds = num/scale |> floor\n",
    "            let newText = text + (HundredsText hundreds) + \" \" + scaleWord + \" \"\n",
    "            let newNum = num - ( hundreds * scale )\n",
    "            (newNum, newText)\n",
    "        else\n",
    "            (num,text)\n",
    "    \n",
    "    if initialNumber = 0 then \"zero\"\n",
    "    else\n",
    "        let num,text = scales |> List.fold( fun acc s -> DoScale s acc ) (initialNumber |> float, \"\")\n",
    "        (text + (HundredsText num)).Trim()       \n",
    "\n",
    "let (|EndsWith|_|) (ending:string) (input : string) = if input.EndsWith(ending) then Some() else None\n",
    "/// Convert any word version of number to ordinal equivalent\n",
    "let MakeOrdinal inputString =\n",
    "    match inputString with\n",
    "    | \"one\" -> \"first\"\n",
    "    | \"two\" -> \"second\"\n",
    "    | \"three\" -> \"third\"\n",
    "    | EndsWith \"ve\" () -> inputString.Replace(\"ve\",\"fth\")\n",
    "    | EndsWith \"y\" () -> inputString.Replace(\"y\",\"ieth\")\n",
    "    | EndsWith \"t\" () -> inputString + \"h\"\n",
    "    | EndsWith \"e\" () -> inputString.Replace(\"e\",\"th\")\n",
    "    | _ -> inputString + \"th\" \n",
    "\n",
    "let numericsRegex = System.Text.RegularExpressions.Regex( \"(?<currency>\\$)?(?<whole>[0-9]+(,[0-9]+)*)(\\.(?<cents>\\d{1,2}))?(?<percent>%)?(?<ordinal>(st|nd|rd|th))?(?<space>\\s)?(?<units>(billion|million|thousand|hundred))?\", System.Text.RegularExpressions.RegexOptions.RightToLeft ||| System.Text.RegularExpressions.RegexOptions.IgnoreCase)\n",
    "/// Replace numeric expressions with words, following South Park conventions\n",
    "let ReplaceNumericsWithWords inputString =\n",
    "    let matches = numericsRegex.Matches(inputString)\n",
    "    let mutable result = inputString\n",
    "    for m in matches do\n",
    "        let words =\n",
    "            if m.Groups.[\"whole\"].Success then\n",
    "                let isCurrency = m.Groups.[\"currency\"].Success\n",
    "                let isPercent = m.Groups.[\"percent\"].Success\n",
    "                let isOrdinal = m.Groups.[\"ordinal\"].Success\n",
    "                let hasUnits = m.Groups.[\"units\"].Success\n",
    "                let whole = m.Groups.[\"whole\"].Value.Replace(\",\",\"\")\n",
    "                let cents = m.Groups.[\"cents\"].Value\n",
    "                let dollarString = \n",
    "                    if hasUnits then \n",
    "                        m.Groups.[\"units\"].Value + \" dollars\"\n",
    "                    else if whole=\"1\" then \n",
    "                        \"dollar\" \n",
    "                    else \n",
    "                        \"dollars\"\n",
    "                //omit cents\n",
    "                if isCurrency && (cents = \"00\" || cents = \"\") then\n",
    "                    (whole |> System.Int32.Parse |> NumbersToText ) + \" \" + dollarString\n",
    "                //omit dollars and cents, e.g. nine ninety-five\n",
    "                else if isCurrency && (cents.EndsWith(\"0\") || cents.EndsWith(\"9\") || cents.EndsWith(\"5\") ) then\n",
    "                    (whole |> System.Int32.Parse |> NumbersToText ) + \" \" + (cents |> System.Int32.Parse |> NumbersToText )\n",
    "                else if isCurrency &&  cents <> \"\" then\n",
    "                    (whole |> System.Int32.Parse |> NumbersToText ) + \" \" + dollarString + \" and \" + (cents |> System.Int32.Parse |> NumbersToText ) + \" cents\"\n",
    "                else if isPercent then\n",
    "                    (whole |> System.Int32.Parse |> NumbersToText ) + \" percent\"\n",
    "                else if isOrdinal then\n",
    "                    whole |> System.Int32.Parse |> NumbersToText  |> MakeOrdinal\n",
    "                else\n",
    "                    (whole |> System.Int32.Parse |> NumbersToText )\n",
    "            else\n",
    "                \"\"\n",
    "        //right to left matching keeps these indices intact\n",
    "        result <- result.Substring(0,m.Index) + words + m.Groups.[\"space\"].Value + result.Substring( m.Index + m.Length )\n",
    "    //\n",
    "    result\n",
    "\n",
    "let CreateLJSpeechTypeMetadata wavDirectory ( records : seq<TTSData> ) =\n",
    "    let rows = \n",
    "        records \n",
    "        |> Seq.map( fun r -> \n",
    "            let cleanText =  r.Text |> CleanText \n",
    "            r.Id + \"|\" + cleanText + \"|\" + ( cleanText |> ReplaceNumericsWithWords ) )\n",
    "\n",
    "    System.IO.File.WriteAllLines(wavDirectory + \"metadata.csv\", rows )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "//Get all alignments for this character\n",
    "let alignments =\n",
    "    System.IO.Directory.GetFiles(alignmentDirectory, \"*.aligned\") \n",
    "    |> Array.collect( fun filePath ->\n",
    "        filePath\n",
    "        |> System.IO.File.ReadAllText\n",
    "        |> Newtonsoft.Json.JsonConvert.DeserializeObject<Alignment[]>\n",
    "    )\n",
    "    |> Array.filter( fun a -> character |> Array.contains  (a.Character.Trim()) ) //all variations of character's name\n",
    "    \n",
    "//\"chunk\" the alignments into clips based on overlapping speech (1 step lookahead); also chunk on clause final punct to improve distribution of clips\n",
    "let ttsData =\n",
    "    alignments\n",
    "    |> Array.collect( fun a ->\n",
    "        [|\n",
    "            if a.Subtitles.Length <> 0 then\n",
    "                let tempList = ResizeArray<Subtitle>()\n",
    "                tempList.Add( a.Subtitles.[0] )\n",
    "                //set a flag to stop if we are long and next is clause final\n",
    "                //let mutable charLength = a.Subtitles.[0].edited_text.Length\n",
    "                //let mutable notLong = true\n",
    "                for i= 1 to a.Subtitles.Length - 1 do\n",
    "                    //Continguous and previous not clause final so accumulate\n",
    "                    if tempList.[tempList.Count - 1].``end`` >= a.Subtitles.[i].start && tempList.[tempList.Count - 1].subtitle |> IsClauseFinalPunct |> not then\n",
    "                        tempList.Add(a.Subtitles.[i])\n",
    "                        //charLength <- charLength + a.Subtitles.[i].edited_text.Length\n",
    "                    //discontinuity or clause final, yield and start new block\n",
    "                    else\n",
    "                        let ttsData = tempList |> MakeTTSData a.Season a.Disc\n",
    "                        tempList.Clear()\n",
    "                        tempList.Add(a.Subtitles.[i])\n",
    "                        //charLength <- a.Subtitles.[i].edited_text.Length\n",
    "                        //notLong <- true\n",
    "                        yield ttsData\n",
    "                //final contents\n",
    "                yield ( tempList |> MakeTTSData a.Season a.Disc )\n",
    "            |]\n",
    "    )\n",
    "    //Conservative: only allow tts data where first/last word have been aligned\n",
    "    |> Array.filter( fun t -> t.FrontAligned = true && t.EndAligned = true )\n",
    "    \n",
    "    //filter by length to get reasonable/gaussian length distribution \n",
    "    //|> Seq.filter( fun r -> \n",
    "    //    let textLength = (r.Text |> CleanText |> ReplaceNumericsWithWords).Length\n",
    "    //    textLength > 0 && textLength < 63)\n",
    "\n",
    "//create a sox script for making wav clips in LJSpeech format\n",
    "ttsData |> CreateSoxSegmentScript wavDirectory\n",
    "                   \n",
    "//create metadata for wav clips in LJSpeech format\n",
    "ttsData |> CreateLJSpeechTypeMetadata wavDirectory\n",
    "\n",
    "//output some diagnostics for R\n",
    "System.IO.File.WriteAllLines(\"diagnostics.tsv\", ttsData |> Seq.map( fun t -> t.Start.ToString() + \"\\t\" + t.Stop.ToString() + \"\\t\" + t.Text + \"\\t\" + t.Text.Length.ToString() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAHgCAMAAABdO/S2AAADAFBMVEUAAAABAQECAgIDAwME\nBAQFBQUGBgYHBwcICAgJCQkKCgoLCwsMDAwNDQ0ODg4PDw8QEBARERESEhITExMUFBQVFRUW\nFhYXFxcYGBgZGRkaGhobGxscHBwdHR0eHh4fHx8gICAhISEiIiIjIyMkJCQlJSUmJiYnJyco\nKCgpKSkqKiorKyssLCwtLS0uLi4vLy8wMDAxMTEyMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk6\nOjo7Ozs8PDw9PT0+Pj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tM\nTExNTU1OTk5PT09QUFBRUVFSUlJTU1NUVFRVVVVWVlZXV1dYWFhZWVlaWlpbW1tcXFxdXV1e\nXl5fX19gYGBhYWFiYmJjY2NkZGRlZWVmZmZnZ2doaGhpaWlqampra2tsbGxtbW1ubm5vb29w\ncHBxcXFycnJzc3N0dHR1dXV2dnZ3d3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGC\ngoKDg4OEhISFhYWGhoaHh4eIiIiJiYmKioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OU\nlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJydnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWm\npqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+wsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4\nuLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLDw8PExMTFxcXGxsbHx8fIyMjJycnK\nysrLy8vMzMzNzc3Ozs7Pz8/Q0NDR0dHS0tLT09PU1NTV1dXW1tbX19fY2NjZ2dna2trb29vc\n3Nzd3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp6enq6urr6+vs7Ozt7e3u\n7u7v7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8/Pz9/f3+/v7////i\nsF19AAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO3dCZwU1Z0H8P/MMDAcIsOhDMwM\nCsihYlCumeEQQXEYEOSQQ0BADKCJMdG4JsgSCDHBIyYxLsvGC6O7GtGNusZgkEgMGGVVBGRV\nAsHgciQQVkAZYJipfVV9TNWrnuquqlf16vX8vp8P3dU1b1696n//mu7q11OkAYCySPYAAMA7\nBBhAYQgwgMIQYACFIcAACkOAARSGAAMoDAEGUBgCDKAwBBhAYQgwgMIQYACFIcAACkOAARSG\nAAMoDAEGUBgCDKAwBBhAYQgwgMIQYACFIcAACkOAARSGAAMoDAEGUBgCDKAwBBhAYQgwgMIQ\nYACFIcAACkOAARSGAAMoDAEGUBgCDKAwBBhAYQgwgMIQYACFIcAACkOAARSGAAMoLBoBXk1E\nb8cWexEN0bSn2YozkgZTs7Rrfsun+LVr2YgOu+xJ5l7IpkBJM7aKqFXYv5kpBNjmZ2zb9Ci/\nFgF2R4GSZgwBTiejap9h654NYTAjidp+bSO/1k2AEyNFgA1RK2n6rXIt3Mcw0UGjDfDu1atX\n13GNwqp2b6Jv2Nd6CXCqvWgsIlxSBFg4W7VTCavabASL7Wu9BLgxi3BJEWDhbNVO7Hjdr6/u\nWtD1qqfZa6/JZNCbHV5W1aX1wDm/i//2nqkdWl7xzodlZYPZjaVE3bXn+/bQtJonLu/SrKTi\noS/Y2p+Ulc2vvuMrLfo8XHdq2QUF3ebuN2/e3F98M0vrf/rhhHYtBv06HuCbiIbrKx8latLQ\n1pIjTZbPMuBHy8om1/7koubnTd6pcfuYRaJbUtNWX5/dt3nHCevY0tu5sWeZ29hPVplaGJJ1\nrG9vq6JlyNZHwGN9m583Y6/G7bwg0Q5w3YTYPUH9vjDd72+2j6+dVaP/xh+MmwX310fqSaLz\ntFMV8VaXfKlp3yS6KHb7WyOMq86f12/d0p8twC+0MlZMaTDAtq3ZAmwdMPudbjONmwUfcvuY\nRaJb0vqtfjPe6Fa29g52/bL2aVNW37qGAmxuz1XROmTLI+B2Y7nwgBZIraMT4Hr11f45u9V9\nwkB2OU/7aINehI3HtL2FbOG8gQXs8juszVH9nju3NTVJVvvctnq172are17egV1+P37Xt2gb\n679jXmxlnLW/jzaWEt2wcW/ip3uasfVFrY1fTBlg+9aSI43vBTfgpXpXOUVsvDSa28csEt2S\nJrf6ErseNLcfu3xO0050J7q4djbrcld9i7j40C3tuSpah2x+BLBWxui+qgVS62gHeAzRDHb1\nMFH7+vcVC4lyf6lpB8uJmrGnNVbV/Ge02gdyktWmzk9s+0i7OPZgmE5UFav2P53RlrGr0o+1\nvZ2IJiQ3zvXHvWFiv3/Wq1rtvQ0GOMXWuHdA3Ab03xn7d+3wAKKz+X3MHhEuaXyrp7uxDtjN\nu4i6nmL/hbKt3cleSD+oNfAe2NqeqyI3ZNMjgAZ/pu3tQtSH33kxoh3gPuy+WnNcO/7iiy+e\nTt4pPdjTqf5LH7F7+wVN6xZ/OptYX+1N7Lru31atYrWrY6v7G9Vuy9537GM/fIj9cK75sArX\nn7XaZ9hrqmX6wsgGA2zfGhdgbgPsd/L+j918KtajZR+zR3RLmtjqNpbyI+zm5+x/zQ3s+mvG\nSAfVag0E2NqeqyI3ZHOAd8Z2oYDfeTGiE+BUb5jm6ndp/uX3bNY/f4jfKafY/fe80ZSV6R7t\nFHt58pJ+a02y2mfHe/3sl7dfzZ6Y49W+lK05zG79RjOeoZPV5vrjqv0J+41t+sLPGwpwiq1Z\nA8xvYKn+apBZx1od5PYxe0S3pImtrjE9wTzCVh9n/01S0x2mFgmxoVvbW6vID9n0CGiur34k\ntjqAWkc7wEeuy43dYT1fT94pf2FXfzKajtCf9Xaym+/qtzYnq93N+OnukcZvtkxUm10a1V6r\nWavN9cdV+zX200P6wn82FOAUW7MGmN/AUv2gKvN6LMCWfcwe0S1pYqs/NgXyTn29/jZpgrlF\nQmzo1vbWKvJD5j9Gij9cAqh1tAPMnnJ/MjJf3+NmexJ3ysm82Msio+n3tP9ja3+r33rJ9MEO\nc5q9XGl/87Of/nO6anP9cdX+kP3Gdn1hZTLAl+s3VzltzVo+fgNcgC37mD2iW9LEVn9FdNbG\nuN16T+ew9XnvmFokxIZubW+tIj/kBgIcQK0jHeAj7K6q0449z977078m75TuRHP1lh+zMq3R\ntHZE39Jv3mSt9nus9SfselK6avP9WatdzZ4yf6QvjIkFeAFRb/3m15y2xpWP24C19NZ9zB7R\nLWliq1vY1T9MI55u/N944UmtgQBb23NPw9yQUwc4iFpHOsC72er/ZOuONyN6yrhT9N3+Knue\n/A9N+1sFe8eyz/jMrTl78ns8z1ptfeLFf7O3KHlpq831x1V7HHsDtl7THqJYgFeQ8ZB4oanT\n1hIjjZeP24C19NZ9zB4RLml8qyfZm+m72M1dF/fqxV7+vsjW/piVdVF9i4T4KylLey7A3JC5\nR0A8wEHUOtIB1uewNul73Qj22iZvj6ax9z6XPnxQ23M2a33BYHbL+FDhI/1DttJ2esDM1f5f\ndjt/YN8cdtXPudpcf1y1t+o9lMY+bmQB/oN+3bGN89YSI43vBbcBrvTWfcwaES5pYqv6AeQh\n80e1Mn7zSEeiCr3TJu/Vt4iLD93SnqsiN2TuEZB4CR1AraMd4J3nUJz+dHY1xZq9Ef/0nuYa\nM9Ie1j9Mp9wJ1mrHjvhR19lEhSccq833x1Xb+ASYckbHAqxdZ9xsNt1pa4mRJspn3QBXeus+\nZo0olzS+1bpZ8UblrLD68ibtMEv+V07XjysmMYnM3J6rIjdk/hEQD3AAtY52gLVjDw3r2rzt\nJTd+oN/YO6lDk7P1Y31/W1JZetaAOYkjeRsnd2k/au3bXLVPrujd8rLbj77bv3//x5yrzfXH\nf5lh3ag27Sp//RbrR5+rd+b+y1q2Hf/Bi/37D2pwa4mRJo/bWDbAl96yj1kjyiVNbvWFqRcW\ndBn1DEvsK6ybiWzND8mYc5lsYUjWsb69/VCkZcj8IyBxEEt8raMRYBHWZtlUJlCxpKEPWf0A\nf3vatPv06/lElbLHAkIoWFJpQ1Y/wLewdx7fXr9hAXsp84zssYAQCpZU2pDVD/CxsvhxgZzv\nyh4KiKFgSaUNWf0AazW/Gn1B8w795+2QPRAQRcGSyhpyFgQYoPFCgAEUhgADKAwBBlAYAgyg\nMAQYQGEIMIDCEGAAhSHAAApDgAEUhgADKAwBBlAYAgygMAQYQGEIMIDCEGAAhfkLcN3h/bWC\nBgIA7vkI8IYZnfOJ8oqnbhA3HABww3OAqyuJOg2qqiorIRp7UuSQACBTngO8hCq3xJZ2TKfl\nooYDAG54DnBZr5rEYt2wCjGDAQB3PAe49ez65UWtBYwEAFzzHODy3meSyyPKhYwFAFzyHOCl\nNGZ7bGnnLFomajgA4Ib3o9BVRKVDxo0f1pVoNI5CA0jh43PgN6YX5RHlFU1ZL244AOCGv5lY\ntQcPYCYWgDyYSgmgMEylBFAYplICKAxTKQEUhqmUAArDVEoAhWEqJYDCMJUSQGGYSgmgMEyl\nBFBYMFMp/3JOYdLZTc+kagIA/gUzlbL2v55LWk6nfG0DABoU/FTKTQgwQFCCn0qJAAMEJvip\nlAgwQGCCn0qJAAMEJviplAgwQGCCn0qZLsCPzLd7xeuoQDkP2aq/VfaQVBL8VMp0AR4wyFbB\nHnO8jgqU03MoV/12P5E9JJUEP5UybYDvs62agwA3Hj1XcSv6IsAuBD+VEgEGJwiwL8H/VUoE\nGJwgwL74CzCL8Cc7apxbIMDgBAH2xXOAFz/GLk4vb0HU9MYjTg0RYHCCAPviOcA0nF3Mp8JJ\nC8qpxwmHhggwOEGAffEV4K05Aw+xxSdpsUNDBBicIMC++ArwKtpkLA/u79AQAQYnCLAvvgK8\nhI4bywtbOjREgMEJAuyLrwA/RduM5WtLHBoiwOAEAfbFe4A7LV+zucPkOrb4VpNJDg0RYHCC\nAPviOcAlOaR7VdNubVawxaEhAgxOEGBfvE/kOLHthRXzhq7TtI593nFqhwCDEwTYF78zsZhd\nzj9GgMEJAuyLgACngQCDyeN3cdr+gGuBALuBAEOoSi+60ip3BtcCAXYDAYZQlT7JrWiKAPuB\nAEOoEGCxEGAIFQIsFgIM7n2xtP4g1O3TXP0qAiwWAgzuHRhdfxBqALk6uSwCLBYCDP64/Lvf\nCLBYCDD4gwBLhQCDPwiwVAgw+IMAS4UAgz8IsFQIMPiDAEuFAIM/CLBUCDD4gwBLhQCDPwiw\nVAgw+IMAS4UAgz8IsFQIMPiDAEuFAIM/CLBUCDD4gwBLhQCDPwiwVAgw+IMAS4UAgz8IsFQI\nMPiDAEuFAIM/CLBUwQT4yx+vSLoZAc5qCLBUwQR4/5B+ST3T/NEzBFhtCLBUeAkN/iDAUiHA\n4A8CLBUCDP4gwFIhwOAPAiwVAgz+IMBSIcDgDwIsFQIM/iDAUiHA4A8CLBUCDP4gwFIhwOAP\nAiwVAgz+IMBSIcDQsLrD+2vTtUGApUKAoQEbZnTOJ8ornrrBsRkCLBUCDClVVxJ1GlRVVVZC\nNNbp+2QIsFQIMKS0hCq3xJZ2TKflDg0RYKkQYEiprFdNYrFuWIVDQwRYKgQYUmo9u355UWuH\nhgiwVAgwpFTe+0xyeUS5Q0MEWCoEGFJaSmO2x5Z2zqJlDg0RYKkQYEipuoqodMi48cO6Eo0O\n9Sh0YYtCq7bPuNlAI4MAQwPemF6UR5RXNGW9YzPhAW4+4Dmrnve42UAjgwBDw2oPHgh/Jlbz\na7kVFQhwwxBgaJiUqZQIsBsIMDRA1lRKBNgNBBhSkjeVEgF2AwGGlORNpUSA3UCAISV5UykR\nYDf8BVjEQQ4EOJLkTaVEgN3wEWBBBzkQ4EiSN5USAXbDc4CFHeRAgCNJ3lRKBNgNzwEWdpAD\nAQ7L6qMuGsubSokAu2EOsKsCCzvIgQCHhQomPnci8+bSplIiwC6YA+yqwMIOciDAYfmXy3Op\n1cxXTmf+Gw1NpdxXkfkJ3DkIsFjmALsqsLCDHAhweA48zErc9qu/T/vRQVLtJztq7GtPPLgi\n6Wb8DyyT9T2wiwILO8iBAIfqwMPDcqnotrfTtVv8GLs4vbwFUdMbjzg1xEtoqWwHsTItsLCD\nHAhwuD5Yej4xPV9ybkbD2cV8Kpy0oJx6OL2xQoClsh+FzrDAwg5yIMDhqfn9bV2IOi547f07\nWuX83rGpHuCtOQMPscUnabFDQwRYKmuAXRTYIOL7oghwWJ6fVUjU7Y5NdfqN9+kWx8Z6gFfR\nJmN5cH+HhgiwVOYAuyqwAVMpVUJ0ydKtiRtH29/v3Hi4/ln/cWN5YUuHhgiwVJaPkdwUGFMp\nlfPAbheN9QA/RduM5WtLHBoiwFKZA+yqwJhKqaB9+tuiJz/MpCl1Wr5mc4fJ+quxt5pMcmiI\nAEtlfQ/sosCYSqmcM9/O0d/Mnke3ZvAxYUmOfiiTXtW0W5sVbHFoiABLZQ6wqwJjKqVyVlLZ\ny+zqzXH0SAatT2x7YcW8oes0rWOfd5zaIcBSmQPsqsCYSqmcS7rHKlF3qdNRZZtdzj9GgKUy\nB9hVgTGVUjktF8QXvn6WwF4RYKnMAXZVYEylVE7PqvjC2B4Ce0WApTIH2FWBMZVSOfPyXjau\nX8u7QWCvCLBU5gC7LDCmUirmUAmN+sGj916b036fwF4RYKnMAXZf4IamUu5uQiYIcETsmW58\nNnR1Jp8TtrFwaIgAS2X5HNhNgQ0NTaWs27Qu6acIcHT87Y///vpfM2q58kKiCy9OcGjoHOBT\nRzjFCLBQ3LeRMi8wplJmuS97ZfanNpzrewHxvsW1QIB9wV+lbESem3plzNxMWv9IRIDb3/uu\nVd58rgUC7IslwG4KjKmUynmEqLC94fxMmq8tEBHgNdwKBFgsc4BdFRhTKZVz0cC9AfSKAEtl\nDrCrAmMqpXIKXguiVwRYKnOAXRUYUymVU/x6EL0iwFKZA+yqwJhKqZwlU4PoFQGWyhxgVwXG\nVErl1My6Zv2+LwwCe0WApTIH2GWBMZVSMW3OTn4YK7BXBFgqcyndFxh/lVIlN9UT2CsCLJU5\nqt4KnO5sSghwdkOApfL+Yqr64bkL3tE296E2Uw46tUOAI6R6+59Ed4kAS8UFOPMCH7mQvdJu\nuu6cDiN7UKfPHRoiwJHx1ylN2bujlZMzne2eEQRYKkuA3RT4dvraB5vLW/Q9qmmP0Z0ODRHg\nqDhQSkOuIm1Nk6L/FdgrAiyVOcCuCtx7ILv4A63Ql4de6tAQAY6Kr9Oj2tOs4G83WyiwVwRY\nKnOAXRW4uX7mlcP0Q335Zj+n3kCAw9JlmGbUV5t8gcBeEWCpzAF2VeDz9bv5zMJX9eUJpQ4N\nEeCo0P9ooVHfW52ecN1CgKXi/yplxgWe0uTVxOL/FFQ5NESAo2Jg/3h9B/cT2CsCLJU5wK4K\nvLsF9V6tL/x+foscp9OBI8BRsZyW1er1/RndJbBXBFgqc4DdFXjXdUXGeZ+/TqWvOLVDgKOi\nZgh1L6d5feiidJNv3ECApbLMhXZbYOMLhVs/rnNshABHxqkHS4io3aJjIjtFgKWyfA4socAI\ncLiO7/iH4B4RYKn4qZRhFxgBVh0CLJXIL5alhgBHxcykBwT2igBLZQ6wjAIjwOFJflm09KsC\ne0WApTIHWEaBEeDwnNRVf/Ziv2FfCuwVAZbKHGAZBUaAw3es+zcF9oYAS5XqPXCYBUaAJbiz\nk8DOEGCpUh7ECrHACLAEtzUX2BkCLFXKAIdYYAQ4dHUbWl8isDsEWKoUAQ61wAhweFrFNCXi\nT/HpBwIslTnAMgqMAIdnbNzsl0T2igBLZQ6wjAIjwKpDgKXCTCzwBwGWCgFuPIotBgrqFQGW\nynJyMwkFRoDDs7AzUcd+xTl03hBmpKBeEWCpzAEOocAnjthceq/tVxDgQPwxd6R+QslPRnf+\n1G9Xx+vrtxYBlskcYIEFNrEEuIjsJtp+BQEOxDVdYlNkq7tN9tnTrhxzAZ3OTYkAB8wcYHEF\nNrMEuOWju3kt7H8RDwEOxLmz4wvziv12tf3dpMfxP7BM5gALLLCJNcD2P5/VEgEOSemI+MJV\nRQJ7xXtgqcwBDqHACLBEU3NfNK5fyR0rsFcEWCpzgEMoMAIs0V8Kc6c+/tsnrs9t9r7AXhFg\nqcwBDqHACLBM711uHHTqvVZkpwiwVJaJHMEXGAGWa9uaH//yrTNCu0SApeJmYgVdYAQ46yDA\nUnk+wXfGEOAICbq+NghwwDyf4DtjCHBkBF9fGwQ4YJ5P8O3o6N13Jc1EgCNCXH3NEGCpPJ/g\n29Hfp12XNMI81Q4Blkhcfc0QYKk8n+A7Y3gJHRUh1NcGAQ6Y5xN8ZwwBjooQ6muDAAfM8wm+\nM4YAR0UI9bVBgAPm/QTfmUKAoyKE+tqICHD3AfM5mzyNNCv5OsF3RhDgqAihvjYiAnxWMZff\nzv/saaRZKeQTfCPAMkk4gbuQAF/FrRiJACeFfIJvBFiysE/gjgAHzBTgfasCeWuBAEdEGPW1\nQYADZgrwBpoUxBYQ4IgIo742CHDATAE+dVH7QwFsAQGOiDDqa4MAB8z8Hvjza/q99OmxL3QC\nt4AAR0UI9bVBgANmDnDHc5J/KVTgFjwEuKJdPxuRH102UiHU1wYBDpi5lDfVE7gFDwHu3m4F\nr2qAwCE1UiHU1wYBDlgiwF8XeUZRCy8B7m5bdR8C7EtI9bVBgAOWCDDN1C8fF/nUHIcAR0FI\n9bVBgANmDfCcAE5WiABHQUj1tUGAA4YANw4IcJZCgBsHBDhLIcCNAwKcpRDgxgEBzlIIcOOA\nAGepZIC7TGPOp2kxAreAAEdBSPW1QYADlgywlcAtIMBREFJ9bRDggCVK+a6VwC0gwFEQUn1t\nEOCABfCmiIMAZzcEWCoEGPxBgKVCgMEfBFgqfwGuO7y/Nl0bBFhdrutrgwAHzEeAN8zonE+U\nVzx1g2MzBFhRXuprgwAHzHOAqyuJOg2qqiorIRp70qEhAqwkb/W1QYAD5jnAS6hyS2xpx3Ra\n7tAQAVaSt/raIMAB8xzgsl41icW6YRUODRFgJXmrrw0CHDDPAW49u355UWuHhgiwkrzV1wYB\nDpjnAJf3PpNcHlHu0BABVpK3+togwAHzHOClNGZ7bGnnLFrm0BABVpK3+togwAHzfhS6iqh0\nyLjxw7oSjcZR6Kzjrb42CHDAfHwO/Mb0ojyivKIp6x2bIcCK8lJfGwQ4YP5mYtUePICZWFnM\ndX3/vptT+BzXHAEWC1MpoWGu69ueeN/lmiPAYmEqJTTAU32fPWKVcwfXHAEWC1MpISVB9c1F\ngIOFqZSQkqD6IsABw1RKSMmxvjW/fi5pOQIsE6ZSQkqO9f20U2HSWWR6gY0Ahw1TKSElQfVF\ngAOGqZSQkqD6IsABw1RKSElQfRHggAU0lfJo/SeBaxFgNQmZKosAByyYqZS7csyTcZwOciDA\nUeZ/qiwCHLCAplL+tX427Br8D6yw2k921Di3QIClwlRKSGnxY+zi9PIWRE1vPOLUEAGWClMp\nISUazi7mU+GkBeXU44RDQwRYKkylhJT0AG/NGXiILT5Jix0aIsBSYSolpKQHeBVtMpYH93do\niABLhamUkJIe4CV03Fhe2NKhIQIsFaZSQkp6gJ+ibcbytSUODRFgqTCVElKiTsvXbO4wuY4t\nvtVkkkNDBFgqTKWElEpic3Fe1bRbmxVscWiIAEuFv0oJqZ3Y9sKKeUPXaVrHPu84tUOApcJf\npYQ0djn/GAGWyl+AM4EAZzcEWCoEGPxBgKVCgMEfBFgqBBj8QYCl8hzgNhYODRHg7IYAS+U5\nwCsvJLrw4gSHhghwdkOApfL+EvrLXuQ0fyMJAc5uEgLc8/wrra6yP6waCx/vgX+EAIOUALct\nvsuqO7+VxsNHgNcWIMAgJcBDuRXXIMDBQYCzGwIsFQIM/iDAUiHA4A8CLBUCDP4gwFIhwOAP\nAiwVAgz+IMBSIcDgDwIsFQIM/iDAUiHA4A8CLBUCDP4gwFIhwOBPFAI84JL5nDfTjDprqBLg\ne3qus/lQ6DjBmygE+NzC66xKbkkz6qyhSoDHkd3ZQscJ3kQiwPzJm6YgwMKICfAY++l5ftPC\n38BACARYKgQY/EGApUKAwR8EWCoEGPxBgKVCgMGfSAb40g79OL+wjzwrIMDgTyQDXHLuCqt+\nc+wjzwoIMPgTzQDzf+h4DgLsFQKc3RBgqRBg8EeNAE8Z/hxnr5YVEGDwR40AX5BbaNXsei0r\nKBzg1XnX2cyp9jdYcE2NANseUjdP1bKCvwDXHd5fm65NYAFeSvxXUOZPpz3phgMu+K9vZAN8\n43D+uzEHNRX5CPCGGZ3zifKKp25wbBZggG2r9iDA4gipb2QD3Mf23ZhJmoo8B7i6kqjToKqq\nshKisU7nWAk3wC+/y9tS5zA4aIig+kY2wBeVciumdeFezs25m/8/eo8WPZ4DvIQqt8SWdkyn\n5Q4Nwwzw2ym+dEgr7Zk+7TBeMAiqrzoB7lfAHU/pYHsk9fg3q5Wr+UfW37SweQ5wWa+axGLd\nsAruh0duqX8iG28pcKXtfWt+qW1V69a2VaVNbKv6298Dj6MrbMe1UmW6hJ9o16/7YFtnE4fZ\nVs0cYFs1r+8827oBM22rhk20raq03xfX9rcfl5P012IE1TeH/1sZOb25FbnduRVNzuNW5Bdz\nK5p15FY078CtaFXIrbA9pApbcSvaN+dWdGzGrShO9VCyatbVqoTfuYntuRZdK/3VyXOAW8+u\nX17UmvuhucCzzdVfNt8ms4e2hDRFY5Pzl3mtkD+C6jvoem5F+TRuRcUUbsXQydyKyydwK0aM\n51ZceQ23YlQVt8J2Z1eN4lZccyW3YvwIbsWEy7kVk4ZyK6bw/w1MK+dWXD+IW+G3vp4DXN77\nTHJ5RLm/QUD0oL5q8BzgpTRme2xp5yyS9L8EBAf1VYP3o9BVRKVDxo0f1pVodEZn+gaVoL5q\n8PE58BvTi/KI8oqmrBc3HIgO1FcF/mZi1R48kHamDqgL9Y284OdCA0BgEGAAhSHAAAoLOcD5\n6SezNGrnhlsO4Rp7fduEfo+HHOAWP7VNTBbp5RRfZhDpp80D7f7db/QNtxzCBVLfS24JoNPJ\nowLodFG30O/xkAOc4ssMIgX9dcJX7F+pEEr5czAGUt+KewLoNJAv9K/qGUCnzhBgNxDgNBDg\nsCHAbiDAaSDAYUOA3UCA00CAw4YAu4EAp4EAhw0BdgMBTgMBDhsC7AYCnAYCHDYE2A0EOA0E\nOGwIsBsIcBoIcNgQYDcQ4DQQ4LCFHODC3wXa/T7aF2j/vysMtHvtp4OD7T9wgdR3+P0BdHrb\nrAA6fbxPAJ06CznAewL+fvjuYLuv3RNs/yeCff4JXiD13X8igE4/PxxAp6c+C6BTZ/g6IYDC\nEGAAhSHAAApDgAEUhgADKAwBBlAYAgygMAQYQGEIMIDCEGAAhSHAAApDgAEUhgADKAwBBlAY\nAgygMAQYQGFhBvjk9ytaVyw7Kay/4tgZ4RZbu0696NrK+Inm0vbscSOJ/gPdiXCFU19fnKvq\ns9MAxptemAEeQ71u6EGjRXV3IqfTcN1j1q5TL7r15YXxqqTt2dtGEv0HuhMhC6e+fqSpqr9O\nAxhvBkIM8Bs05oxWczVtENTfNlqeouvUiy69dm+v+Kle0/bsaSP1/Qe4E2ELp74+pKuqz06F\njzcjIQZ4Om1nl+/TTEH9vUBrUnSdetGlguS5mtP27Gkj9f0HuBNhC6e+PqSrqs9OhY83IyEG\nuFNJ7KqzoP5W0Oanv/eL7VzXqRddOnnyZPx1UdqePW2kvv8AdyJs4dTXh3RV9dmp8PFmJLwA\n1+YNMa4H5deJ6XAedWDPfjkLT5u7Tr3oofeLjaqk7dnzRmL9B7wTYQqnvj77dKqqz04DGW96\n4QX4II0zrqtI0B/0HEqTtx0S8/AAAAWJSURBVB774wD6gbnr1Iseeo9VJW3PnjcSr3qwOxGm\ncOrrs0+nqvrsNJDxphdegA/QeOO6ivaL6XDdq/rz26HClrWmrlMveug9VpW0PXveSLzqwe5E\nmMKpr88+narqs9NAxptemC+hhxnXZXli//j3JPrE1HXqRQ/dJl5spenZ80biVQ92J8IUTn19\nduZUVZ+dJggdb3ohHsQq6mpclRaL7XYB7TB3nXrRvXhV0vbsdSPWqge0E6EKp77+OFbVZ6dx\nQsebXogBnkJ/Zpf/Q4LOKvXnjrca1xVNa8xdp150L16VtD173Uis/4B3IlTh1Ncfx6r66zSQ\n8aYXYoDX0w3s8nphn273KfgTu/wlzbV0nXrRvXip0/bsdSPx/oPdiVCFU19/HKvqs9Mgxpte\niAGuq6SRdw+nMaL6e7ugyYSbh1KPI5auUy+6F69K2p69biTef7A7Eapw6uuPY1V9dhrEeNML\ncy509ffKWpcJnOH9/sTiFpctOsF1nXrRtcQbm7Q9e9xIov9AdyJc4dTXF+eq+uw0gPGmh68T\nAigMAQZQGAIMoDAEGEBhCDCAwhBgAIUhwAAKQ4ABFIYAAygMAQZQGAIMoDAEGEBhCDCAwhBg\nAIUhwAAKQ4ABFIYAAygMAQZQGAIMoDAEGEBhCDCAwhBgAIUhwAAKQ4ABFIYAAygMAQZQGAIM\noDAEGEBhCDCAwhBgAIUhwAAKQ4ABFIYAAyisEQZ4SDG7eKK0xS79xi5yOI36TDpj/APVpKrx\nRhoa/+mbVClrYMI10gAfaFK86LCm7b+9D1327X+katWXXk8GWF8GlaSqcV1pzr7YT79Fj8cW\nVtMr8sYoRiMN8Jv0AFva2rbNtTS7ZdHBFK0QYJWlrPE/0c9iPz0v/4hx/XFLBFhBenE30Cq2\nNKzdXvbyanPe/BStDh88lQywvgwqSVnjD6jC+OH7NMa4rv4KIcBK+Whi587X7WHFnUnMxzX5\n8433RxV9NG1hm5Pf6NVhwsEvFnQ/64ptrO1N9EUywPoyqMGhxlrvnL16k8X0pNH05hY3IMAq\n+WOr3CtuKO3YpVh78zs0e/XRk/kzjOJWf8kC3KpyyVv35/btf8emh/K71SLAinKqsfZ9elBv\nc1HTz/Wr5+mxFQiwQuouy31J074YQcmXVwObvpo4Cr2Q7maX4+gWdjmLdiPAanKssfZnKmOX\nn9A4/caeNtM0BFglm2mafrWtvrgftKJe9Kzx/nYhfcgu76SN7PIeehcBVpNjjTVtAH2qsdQ+\nzRZPD+p6FAFWytPxDw86Jour7fnuOURtbzuuB/gQu/0d+rOmVxgBVpRjjTXtQbqf/Z9ccIwt\n3pn/joYAK+UB+q1x3a++uJq2k+7rScP1AB/W9ADrn/wjwMpyrLGm7csdoH2WM4Etrc+5T0OA\n1fIresK47mwuLnt/dGo07UWAs4NjjZkraPfP6VlNT3rCo5KGKkgjCvB7dL1+tTMnUdwNY98z\njlD+il5CgLODY42ZX9CKK5rrxVy3UDeIRi/cKHXAvjWiAGsDcn+jadVVyQMcb7ILvbgr6b8R\n4CzhVGPmSNML8ibXt8ZLaKVsbJU7al73VslZOkfbXHyYFffQBZ2rEeAs4VRj3TVEa+pbI8Bq\n+WhCcceJ7//L7MT7o9W5nWbQgnML/st6EOv+kh0IsKocaqx7hlp+Wd8YAVbc21PPp943fiR7\nGBCgLK9x4w5wmu8DQ1bI6hojwFlcXDBkdY0be4ABlIYAAygMAQZQGAIMoDAEGEBhCDCAwhBg\nAIUhwAAKQ4ABFIYAAygMAQZQGAIMoDAEGEBhCDCAwhBgAIUhwAAKQ4ABFIYAAygMAQZQGAIM\noDAEGEBhCDCAwhBgAIUhwAAKQ4ABFIYAAygMAQZQGAIMoLD/B+AJPLsfi+l5AAAAAElFTkSu\nQmCC",
      "text/plain": [
       "Plot with title “Histogram of text lengths”"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- read.table(\"diagnostics.tsv\",sep=\"\\t\",header=F,quote=\"\")\n",
    "df$milli <- df$V2 - df$V1\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "op <- par(mfrow=c(1,2))\n",
    "hist(df$milli,main=\"Histogram of durations\")\n",
    "hist(df$V4,main=\"Histogram of text lengths\")\n",
    "par(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "ifsharp"
   },
   "source": [
    "## Create wav clips\n",
    "\n",
    "Simply run the `segsox.sh` script to create the wavs directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cd /y/south-park-1-to-20\n",
    "bash segsox.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Manually correct metadata and/or wavs\n",
    "\n",
    "Any numeric conversion should be checked. Most will be OK, but the dollars/cents rules are heuristics. Example problems:\n",
    "\n",
    "- $300,000 building -> three hundred thousand dollar~~s~~ building (currency as modifier not noun)\n",
    "\n",
    "- $2.25 -> two twenty five; actual might have been two dollars and twenty five cents\n",
    "\n",
    "In general, it would be wise to correct the output data using something like https://github.com/ozdefir/finetuneas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "java"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "That's it, the dataset is made. The next step is to use a LJSpeech-friendly TTS training algorithm like [mozilla/TTS](https://github.com/mozilla/TTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "ifsharp",
     "ifsharp",
     "",
     ""
    ]
   ],
   "version": "0.9.15.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
